from typing import Optional, Set
from pathlib import Path
import httpx, asyncio

from fastapi import APIRouter, Depends, Query
from sqlalchemy import select, update, delete
from sqlalchemy.ext.asyncio import AsyncSession
from starlette.responses import JSONResponse

from core.database import get_db, AsyncSessionLocal
from models import Provider, Product
from providers import bunjang
from core.logger import setup_logger
from providers.bunjang import fetch_products, fetch_product_detail, upsert_product, delete_product_by_pid
from utils.string import parse_korean_number
from utils.time import normalize_datetime, safe_parse_datetime

logger = setup_logger(__name__)  # í˜„ì¬ íŒŒì¼ëª… ê¸°ì¤€ ì´ë¦„ ì§€ì •

router = APIRouter(prefix="/sync", tags=["Sync"])

keyword_queue: list[str] = []         # ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•Šì€ í‚¤ì›Œë“œ
total_keywords: int = 0               # ì „ì²´ í‚¤ì›Œë“œ ìˆ˜
batch_size: int = 5
processed_count: int = 0             # í˜„ì¬ê¹Œì§€ ì²˜ë¦¬ëœ ìˆ˜
is_running: bool = False             # ì‹¤í–‰ ì¤‘ ì—¬ë¶€
pid_lock = asyncio.Lock()             # ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ lock


@router.post("/categories")
async def sync_categories(
    code: str = Query("BUNJANG", description="ê³µê¸‰ì ì½”ë“œ"),
    #code: str = Query(..., description="ê³µê¸‰ì ì½”ë“œ"),
    db: AsyncSession = Depends(get_db)
):
    await bunjang.fetch_categories(code, db)
    return {"message": f"{code} categories synced."}

@router.post("/products")
async def sync_products(
    code: str = Query("BUNJANG", description="ê³µê¸‰ì ì½”ë“œ"),
    # keyword: Optional[str] = Query(None, description="í‚¤ì›Œë“œ"),
    category: Optional[str] = Query("750800", description="ì¹´í…Œê³ ë¦¬"),
    db: AsyncSession = Depends(get_db)
):
    global keyword_queue, total_keywords, processed_count, is_running
    all_product_pids: list[dict[str, str]] = []    # pid ì¤‘ë³µ ì œê±°ìš© list

    if is_running:
        return JSONResponse(
            status_code=409,
            content={
                "message": "ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
                "progress": f"{processed_count}/{total_keywords}"
            }
        )

    result = await db.execute(select(Provider).where(Provider.code == code))
    provider = result.scalars().first()

    # í‚¤ì›Œë“œ ë¡œë”©
    text = Path("./list.txt").read_text(encoding="utf-8")
    keywords = []
    for line in text.splitlines():
        for item in line.split(","):
            kw = item.strip()
            if kw and kw not in keywords:
                keywords.append(kw)

    keyword_queue = keywords
    total_keywords = len(keyword_queue)
    processed_count = 0
    all_product_pids.clear()

    async def sync_detail_and_save(pid: str):
        async with AsyncSessionLocal() as db:
            detail = await fetch_product_detail(pid, db)
            if detail:
                await upsert_product(detail, db)

    async def sync_update_deleted(pid: str):
        async with AsyncSessionLocal() as db:
            await delete_product_by_pid(pid, db)

    async def run_keyword_sync():
        global is_running, processed_count
        nonlocal all_product_pids
        is_running = True
        try:
            logger.info("ğŸš€ í‚¤ì›Œë“œ ë™ê¸°í™” ì‹œì‘")

            # 1. pid ìˆ˜ì§‘
            async def worker(worker_id: int):
                global keyword_queue, processed_count
                while True:
                    try:
                        keyword = keyword_queue.pop(0)
                    except IndexError:
                        break
                    try:
                        if not provider or provider.code == "BUNJANG":
                            all_product_pids.extend(await fetch_products(keyword=keyword, category=category))
                            processed_count += 1
                    except Exception:
                        logger.exception(f"[{keyword}] âŒ ì‘ì—…ì {worker_id} ì—ëŸ¬ ë°œìƒ")

            tasks = [asyncio.create_task(worker(i)) for i in range(batch_size)]
            await asyncio.gather(*tasks)

            # 1. DB ì¡°íšŒ
            async with AsyncSessionLocal() as new_db:
                dbProducts = select(Product).where(Product.status != 9)
                dbResult = await new_db.execute(dbProducts)
                dbProductsList = dbResult.scalars().all()
                dbList = [{"pid": p.pid, "updated_dt": p.updated_dt} for p in dbProductsList]

            # safe_parse_datetime ë“±ìœ¼ë¡œ ë‚ ì§œë¥¼ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ í†µì¼í•´ì•¼ í•¨
            src_set = set((item["pid"], safe_parse_datetime(item["updated_dt"])) for item in all_product_pids)
            db_set = set((item["pid"], normalize_datetime(item["updated_dt"])) for item in dbList)

            # 1. ì‹ ê·œ/ì—…ë°ì´íŠ¸ ëŒ€ìƒ (all_product_pidsì—ë§Œ ìˆìŒ)
            only_src = src_set - db_set
            # 2. ì‚­ì œ ëŒ€ìƒ (DBì—ë§Œ ìˆìŒ)
            only_db = db_set - src_set

            logger.info(f"âœ… ì‹ ê·œ/ì—…ë°ì´íŠ¸ ëŒ€ìƒ: {len(only_src)}ê°œ, ì‚­ì œ ëŒ€ìƒ: {len(only_db)}ê°œ")

            # 2. ìƒì„¸ ì •ë³´ upsert
            srcs = list(only_src)
            src_chunks = [srcs[i:i+batch_size] for i in range(0, len(srcs), batch_size)]
            for chunk in src_chunks:
                detail_tasks = [
                    asyncio.create_task(sync_detail_and_save(pid))
                    for pid, updated_dt in chunk
                ]
                await asyncio.gather(*detail_tasks)

            # 3. ì‚­ì œ ì²˜ë¦¬ë„ batchë¡œ ì‹¤í–‰
            dbs = list(only_db)
            db_chunks = [dbs[i:i+batch_size] for i in range(0, len(dbs), batch_size)]
            for chunk in db_chunks:
                delete_tasks = [
                    asyncio.create_task(sync_update_deleted(pid))
                    for pid, updated_dt in chunk
                ]
                await asyncio.gather(*delete_tasks)

            logger.info("âœ… ìƒì„¸ upsert ì™„ë£Œ.")

        except Exception:
            logger.exception("âŒ run_keyword_sync ì—ëŸ¬ ë°œìƒ")
        finally:
            is_running = False

    asyncio.create_task(run_keyword_sync())
    #logger.info(f"total_keywords: {total_keywords}, keyword_queue: {keyword_queue}")
    return {"message": f"{total_keywords}ê°œ í‚¤ì›Œë“œ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ë° ìƒì„¸ upsert ì‹œì‘"}
