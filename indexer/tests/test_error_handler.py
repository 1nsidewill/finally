"""
ErrorHandler í…ŒìŠ¤íŠ¸

ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬, ë¡œê¹…, failed_operations í…Œì´ë¸” ê¸°ë¡ì„ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import os
from unittest.mock import AsyncMock, MagicMock
from typing import Dict, Any

from src.services.error_handler import (
    ErrorHandler, ErrorContext, FailedOperation, 
    ErrorCategory, ErrorSeverity
)
from src.database.postgresql import PostgreSQLManager

async def test_error_categorization():
    """ì˜¤ë¥˜ ìë™ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¥ ì˜¤ë¥˜ ìë™ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸!")
    
    error_handler = ErrorHandler()
    
    # ë‹¤ì–‘í•œ ì˜¤ë¥˜ íƒ€ì…ë³„ í…ŒìŠ¤íŠ¸
    test_cases = [
        (ValueError("product_idê°€ í•„ìš”í•©ë‹ˆë‹¤"), ErrorCategory.VALIDATION, ErrorSeverity.MEDIUM),
        (ConnectionError("PostgreSQL ì—°ê²° ì‹¤íŒ¨"), ErrorCategory.DATABASE, ErrorSeverity.HIGH),
        (Exception("API key is invalid"), ErrorCategory.AUTHENTICATION, ErrorSeverity.HIGH),
        (Exception("Rate limit exceeded"), ErrorCategory.RATE_LIMIT, ErrorSeverity.LOW),
        (TimeoutError("Network timeout"), ErrorCategory.NETWORK, ErrorSeverity.MEDIUM),
        (RuntimeError("ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"), ErrorCategory.UNKNOWN, ErrorSeverity.MEDIUM),
    ]
    
    for exception, expected_category, expected_severity in test_cases:
        category, severity = error_handler._categorize_error(exception)
        assert category == expected_category, f"ì¹´í…Œê³ ë¦¬ ë¶ˆì¼ì¹˜: {category} != {expected_category}"
        assert severity == expected_severity, f"ì‹¬ê°ë„ ë¶ˆì¼ì¹˜: {severity} != {expected_severity}"
        
        print(f"  âœ… {type(exception).__name__}: {category.value}({severity.value})")
    
    print(f"  ğŸ¯ {len(test_cases)}ê°œ ì˜¤ë¥˜ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

async def test_error_context():
    """ErrorContext ë°ì´í„° êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ErrorContext êµ¬ì¡° í…ŒìŠ¤íŠ¸!")
    
    # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸
    context = ErrorContext(
        job_id="test_job_123",
        job_type="sync",
        product_id="product_456",
        operation_step="embedding_generation",
        additional_data={"retry_count": 1, "batch_id": "batch_789"}
    )
    
    assert context.job_id == "test_job_123"
    assert context.additional_data["retry_count"] == 1
    
    # ì¶”ê°€ ë°ì´í„° ì—†ëŠ” ê²½ìš°
    simple_context = ErrorContext(
        job_id="simple_job",
        job_type="delete",
        product_id="product_999",
        operation_step="vector_deletion"
    )
    
    assert simple_context.additional_data == {}
    
    print(f"  âœ… ErrorContext êµ¬ì¡° ê²€ì¦ ì™„ë£Œ")
    print(f"  - Job ID: {context.job_id}")
    print(f"  - Operation Step: {context.operation_step}")
    print(f"  - Additional Data: {context.additional_data}")

async def test_failed_operation_creation():
    """FailedOperation ê°ì²´ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ FailedOperation ìƒì„± í…ŒìŠ¤íŠ¸!")
    
    failed_op = FailedOperation(
        id="failure_123",
        job_id="job_456",
        job_type="update",
        product_id="product_789",
        error_category=ErrorCategory.DATABASE,
        error_severity=ErrorSeverity.HIGH,
        error_message="PostgreSQL ì—°ê²° ì‹¤íŒ¨",
        error_details='{"exception_type": "ConnectionError", "traceback": "..."}',
        operation_step="data_fetch",
        retry_count=1,
        max_retries=3
    )
    
    assert failed_op.id == "failure_123"
    assert failed_op.error_category == ErrorCategory.DATABASE
    assert failed_op.error_severity == ErrorSeverity.HIGH
    assert failed_op.created_at is not None  # ìë™ ìƒì„±ë¨
    assert failed_op.additional_data == {}  # ê¸°ë³¸ê°’
    
    print(f"  âœ… FailedOperation ê°ì²´ ìƒì„± ì™„ë£Œ")
    print(f"  - ID: {failed_op.id}")
    print(f"  - ì¹´í…Œê³ ë¦¬: {failed_op.error_category.value}")
    print(f"  - ì‹¬ê°ë„: {failed_op.error_severity.value}")
    print(f"  - ìƒì„± ì‹œê°„: {failed_op.created_at}")

async def test_error_details_extraction():
    """ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸!")
    
    error_handler = ErrorHandler()
    
    # ë³µì¡í•œ ì˜ˆì™¸ ìƒì„±
    try:
        raise ValueError("ì˜ëª»ëœ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤")
    except Exception as e:
        error_details = error_handler._extract_error_details(e)
        
    # JSON íŒŒì‹± í™•ì¸
    details_dict = json.loads(error_details)
    
    assert details_dict['exception_type'] == 'ValueError'
    assert 'traceback' in details_dict
    assert 'timestamp' in details_dict
    assert len(details_dict['exception_args']) > 0
    
    print(f"  âœ… ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")
    print(f"  - Exception Type: {details_dict['exception_type']}")
    print(f"  - Args: {details_dict['exception_args']}")
    print(f"  - Timestamp: {details_dict['timestamp']}")

async def test_error_handling_workflow():
    """ì „ì²´ ì˜¤ë¥˜ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ì˜¤ë¥˜ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸!")
    
    # Mock PostgreSQL ë§¤ë‹ˆì €
    mock_postgresql = AsyncMock(spec=PostgreSQLManager)
    mock_conn = AsyncMock()
    mock_conn.execute = AsyncMock()
    mock_postgresql.get_connection = AsyncMock(return_value=mock_conn)
    
    error_handler = ErrorHandler()
    error_handler.postgresql_manager = mock_postgresql
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì™¸ì™€ ì»¨í…ìŠ¤íŠ¸
    test_exception = ConnectionError("Redis ì—°ê²° ì‹¤íŒ¨")
    context = ErrorContext(
        job_id="workflow_test_1",
        job_type="sync",
        product_id="test_product",
        operation_step="redis_polling",
        additional_data={"queue_name": "sync_queue"}
    )
    
    # ì˜¤ë¥˜ ì²˜ë¦¬ ì‹¤í–‰
    failed_op = await error_handler.handle_error(test_exception, context)
    
    # ê²°ê³¼ ê²€ì¦
    assert failed_op.job_id == "workflow_test_1"
    assert failed_op.error_category == ErrorCategory.NETWORK
    assert failed_op.error_severity == ErrorSeverity.MEDIUM
    assert "Redis ì—°ê²° ì‹¤íŒ¨" in failed_op.error_message
    
    # Mock í˜¸ì¶œ ê²€ì¦
    mock_postgresql.get_connection.assert_called()
    mock_conn.execute.assert_called()  # INSERT ì¿¼ë¦¬ ì‹¤í–‰ë¨
    
    print(f"  âœ… ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"  - Failed Operation ID: {failed_op.id}")
    print(f"  - ë¶„ë¥˜: {failed_op.error_category.value}")
    print(f"  - DB ê¸°ë¡: í˜¸ì¶œë¨")

async def test_error_statistics():
    """ì˜¤ë¥˜ í†µê³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ì˜¤ë¥˜ í†µê³„ í…ŒìŠ¤íŠ¸!")
    
    error_handler = ErrorHandler()
    
    # ì´ˆê¸° í†µê³„ í™•ì¸
    initial_stats = error_handler.get_error_stats()
    assert initial_stats['total_errors'] == 0
    assert initial_stats['retry_success_rate'] == 0
    
    # ìˆ˜ë™ìœ¼ë¡œ í†µê³„ ë°ì´í„° ì¶”ê°€
    error_handler._update_error_stats(ErrorCategory.DATABASE, ErrorSeverity.HIGH)
    error_handler._update_error_stats(ErrorCategory.NETWORK, ErrorSeverity.MEDIUM)
    error_handler._update_error_stats(ErrorCategory.VALIDATION, ErrorSeverity.LOW)
    error_handler.error_stats['retry_success_count'] = 1
    
    # í†µê³„ ê²€ì¦
    stats = error_handler.get_error_stats()
    assert stats['total_errors'] == 3
    assert stats['by_category']['database'] == 1
    assert stats['by_category']['network'] == 1
    assert stats['by_severity']['high'] == 1
    assert stats['retry_success_rate'] == 33.33333333333333  # 1/3 * 100
    
    print(f"  âœ… í†µê³„ ê¸°ëŠ¥ ê²€ì¦ ì™„ë£Œ:")
    print(f"    - ì´ ì˜¤ë¥˜: {stats['total_errors']}ê°œ")
    print(f"    - ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {stats['by_category']['database']}ê°œ")
    print(f"    - ë†’ì€ ì‹¬ê°ë„: {stats['by_severity']['high']}ê°œ")
    print(f"    - ì¬ì‹œë„ ì„±ê³µë¥ : {stats['retry_success_rate']:.1f}%")
    
    # í†µê³„ ì´ˆê¸°í™”
    error_handler.reset_stats()
    reset_stats = error_handler.get_error_stats()
    assert reset_stats['total_errors'] == 0
    
    print(f"  âœ… í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")

async def test_logging_setup():
    """ë¡œê¹… ì„¤ì • í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ë¡œê¹… ì„¤ì • í…ŒìŠ¤íŠ¸!")
    
    error_handler = ErrorHandler()
    
    # ë¡œê±° ì¡´ì¬ í™•ì¸
    assert error_handler.error_logger is not None
    assert error_handler.perf_logger is not None
    
    # ë¡œê·¸ íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸
    logs_dir = "logs"
    assert os.path.exists(logs_dir), f"ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {logs_dir}"
    
    print(f"  âœ… ë¡œê¹… ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    print(f"  - Error Logger: ì„¤ì •ë¨")
    print(f"  - Performance Logger: ì„¤ì •ë¨")
    print(f"  - Logs Directory: {logs_dir}")

async def test_retry_mechanism():
    """ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸!")
    
    # Mock PostgreSQL ë§¤ë‹ˆì €
    mock_postgresql = AsyncMock(spec=PostgreSQLManager)
    mock_conn = AsyncMock()
    
    # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì‹¤íŒ¨ ì‘ì—… ë°ì´í„° Mock
    retry_data = [{
        'id': 'retry_test_1',
        'job_id': 'job_retry',
        'retry_count': 1,
        'max_retries': 3,
        'resolved_at': None
    }]
    
    mock_conn.fetch = AsyncMock(return_value=retry_data)
    mock_conn.execute = AsyncMock()
    mock_postgresql.get_connection = AsyncMock(return_value=mock_conn)
    
    error_handler = ErrorHandler()
    error_handler.postgresql_manager = mock_postgresql
    
    # ì¬ì‹œë„ ì‹¤í–‰
    retry_result = await error_handler.retry_failed_operation('retry_test_1')
    
    # ê²°ê³¼ ê²€ì¦
    assert retry_result == True, "ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
    
    # Mock í˜¸ì¶œ ê²€ì¦
    mock_conn.fetch.assert_called()  # SELECT ì¿¼ë¦¬
    assert mock_conn.execute.call_count >= 1  # UPDATE ì¿¼ë¦¬
    
    print(f"  âœ… ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"  - ì¬ì‹œë„ ê²°ê³¼: {retry_result}")
    print(f"  - DB ì—…ë°ì´íŠ¸: í˜¸ì¶œë¨")

async def test_comprehensive_error_scenarios():
    """í¬ê´„ì ì¸ ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”¥ í¬ê´„ì ì¸ ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸!")
    
    error_scenarios = [
                 {
             'name': 'PostgreSQL ì—°ê²° ì‹¤íŒ¨',
             'exception': ConnectionError("PostgreSQL connection failed"),
             'expected_category': ErrorCategory.DATABASE,
             'expected_severity': ErrorSeverity.HIGH
         },
                 {
             'name': 'OpenAI API í‚¤ ì˜¤ë¥˜',
             'exception': Exception("Invalid API key provided"),
             'expected_category': ErrorCategory.AUTHENTICATION,
             'expected_severity': ErrorSeverity.HIGH
         },
         {
             'name': 'ì†ë„ ì œí•œ ì´ˆê³¼',
             'exception': Exception("Rate limit exceeded"),
             'expected_category': ErrorCategory.RATE_LIMIT,
             'expected_severity': ErrorSeverity.LOW
         },
         {
             'name': 'ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨',
             'exception': ValueError("product_id is required"),
             'expected_category': ErrorCategory.VALIDATION,
             'expected_severity': ErrorSeverity.MEDIUM
         },
         {
             'name': 'ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ',
             'exception': TimeoutError("Request timed out"),
             'expected_category': ErrorCategory.NETWORK,
             'expected_severity': ErrorSeverity.MEDIUM
         }
    ]
    
    error_handler = ErrorHandler()
    mock_postgresql = AsyncMock(spec=PostgreSQLManager)
    mock_conn = AsyncMock()
    mock_conn.execute = AsyncMock()
    mock_postgresql.get_connection = AsyncMock(return_value=mock_conn)
    error_handler.postgresql_manager = mock_postgresql
    
    processed_scenarios = []
    
    for scenario in error_scenarios:
        context = ErrorContext(
            job_id=f"scenario_{len(processed_scenarios)}",
            job_type="test",
            product_id="test_product",
            operation_step="scenario_test"
        )
        
        failed_op = await error_handler.handle_error(scenario['exception'], context)
        
        # ë¶„ë¥˜ ê²€ì¦
        assert failed_op.error_category == scenario['expected_category'], f"ì¹´í…Œê³ ë¦¬ ë¶ˆì¼ì¹˜: {failed_op.error_category} != {scenario['expected_category']}"
        assert failed_op.error_severity == scenario['expected_severity'], f"ì‹¬ê°ë„ ë¶ˆì¼ì¹˜: {failed_op.error_severity} != {scenario['expected_severity']}"
        
        processed_scenarios.append({
            'name': scenario['name'],
            'category': failed_op.error_category.value,
            'severity': failed_op.error_severity.value,
            'success': True
        })
    
    print(f"  âœ… {len(processed_scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
    for scenario in processed_scenarios:
        print(f"    âœ… {scenario['name']}: {scenario['category']}({scenario['severity']})")

async def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ErrorHandler ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘!\n")
    
    test_functions = [
        test_error_categorization,
        test_error_context,
        test_failed_operation_creation,
        test_error_details_extraction,
        test_error_handling_workflow,
        test_error_statistics,
        test_logging_setup,
        test_retry_mechanism,
        test_comprehensive_error_scenarios,
    ]
    
    passed = 0
    total = len(test_functions)
    
    for test_func in test_functions:
        try:
            await test_func()
            passed += 1
        except Exception as e:
            print(f"âŒ {test_func.__name__} ì‹¤íŒ¨: {e}")
    
    print(f"\nğŸ¯ ErrorHandler í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ErrorHandler êµ¬í˜„ì´ ì™„ë²½í•©ë‹ˆë‹¤!")
    else:
        print(f"âš ï¸ {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main()) 