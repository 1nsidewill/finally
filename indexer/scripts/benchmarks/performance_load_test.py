#!/usr/bin/env python3
"""
30k ë§¤ë¬¼ ì²˜ë¦¬ í†µí•© ë¶€í•˜ í…ŒìŠ¤íŠ¸
ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import asyncio
import time
import json
import psutil
import threading
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import logging
import signal
import sys

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤
from src.database.postgresql import PostgreSQLManager
from src.database.qdrant import QdrantManager  
from src.database.redis import RedisManager
from src.services.embedding_service import EmbeddingService
from src.services.text_preprocessor import ProductTextPreprocessor
from src.monitoring.metrics import get_metrics
from src.config import get_settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class LoadTestMetrics:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    start_time: float
    end_time: Optional[float] = None
    total_jobs: int = 0
    completed_jobs: int = 0
    failed_jobs: int = 0
    jobs_per_second: float = 0.0
    avg_processing_time: float = 0.0
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    redis_connections_used: int = 0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class MockProductGenerator:
    """ì‹¤ì œ ë§¤ë¬¼ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ëª¨ì˜ ë°ì´í„° ìƒì„±ê¸°"""
    
    def __init__(self):
        self.brands = ["YAMAHA", "HONDA", "KAWASAKI", "SUZUKI", "DUCATI", "BMW", "KTM"]
        self.models = ["FZ-25", "CB300R", "NINJA 400", "GSX-R125", "MONSTER", "G310R", "RC200"]
        self.conditions = ["ë§¤ìš°ì–‘í˜¸", "ì–‘í˜¸", "ë³´í†µ", "ìˆ˜ë¦¬í•„ìš”"]
        
    def generate_product(self, uid: int) -> Dict[str, Any]:
        """ë‹¨ì¼ ë§¤ë¬¼ ë°ì´í„° ìƒì„±"""
        import random
        
        brand = random.choice(self.brands)
        model = random.choice(self.models)
        year = random.randint(2015, 2024)
        price = random.randint(150, 800)  # 150~800ë§Œì›
        mileage = random.randint(0, 50000)  # 0~50,000km
        condition = random.choice(self.conditions)
        
        return {
            "uid": uid,
            "title": f"{brand} {model} {year}ë…„ì‹",
            "content": f"ì£¼í–‰ê±°ë¦¬ {mileage:,}km, ìƒíƒœ {condition}, ì •ê¸°ì ê²€ ì™„ë£Œ",
            "price": str(price),
            "year": str(year),
            "mileage": str(mileage),
            "brand": brand,
            "model": model,
            "is_conversion": False,  # ìƒˆë¡œìš´ ë°ì´í„°
            "created_at": datetime.now().isoformat()
        }
    
    def generate_batch(self, start_uid: int, batch_size: int) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ë§¤ë¬¼ ë°ì´í„° ìƒì„±"""
        return [
            self.generate_product(start_uid + i) 
            for i in range(batch_size)
        ]

class LoadTestRunner:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.config = get_settings()
        self.product_generator = MockProductGenerator()
        self.text_preprocessor = ProductTextPreprocessor()
        self.embedding_service = EmbeddingService()
        self.redis_manager = RedisManager()
        
        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        self.metrics = LoadTestMetrics(start_time=time.time())
        self.is_running = True
        self.processed_jobs = []
        
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
    def _signal_handler(self, signum, frame):
        """Graceful shutdown"""
        logger.info(f"ì‹ í˜¸ {signum} ìˆ˜ì‹ , í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")
        self.is_running = False
        
    async def monitor_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        while self.is_running:
            try:
                # CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_info = psutil.virtual_memory()
                
                self.metrics.cpu_usage_percent = cpu_percent
                self.metrics.memory_usage_mb = memory_info.used / 1024 / 1024
                
                # Redis ì—°ê²° ìˆ˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
                self.metrics.redis_connections_used = len(self.redis_manager._connection_pool._available_connections) if hasattr(self.redis_manager, '_connection_pool') else 0
                
                # 5ì´ˆë§ˆë‹¤ ë¡œê·¸
                if int(time.time()) % 5 == 0:
                    logger.info(f"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ - CPU: {cpu_percent:.1f}%, ë©”ëª¨ë¦¬: {self.metrics.memory_usage_mb:.1f}MB")
                
                await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(5)
    
    async def simulate_job_processing(self, job_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ ì‘ì—… ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        job_start_time = time.time()
        
        try:
            # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            processed_text = self.text_preprocessor.preprocess_product_data(job_data)
            
            # 2. ì„ë² ë”© ìƒì„± (ì‹¤ì œ API í˜¸ì¶œì€ ë¹„ìš© ë•Œë¬¸ì— ëª¨ì˜)
            # embedding = self.embedding_service.create_embedding(processed_text)
            # ëŒ€ì‹  ëœë¤ ë²¡í„° ìƒì„± (3072 ì°¨ì›)
            import numpy as np
            mock_embedding = np.random.random(3072).tolist()
            
            # 3. ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ì„ë² ë”© API í˜¸ì¶œ ì‹œê°„ ê·¼ì‚¬)
            await asyncio.sleep(0.1)  # 100ms ì‹œë®¬ë ˆì´ì…˜
            
            job_end_time = time.time()
            processing_time = job_end_time - job_start_time
            
            result = {
                "job_id": job_data["uid"],
                "status": "completed",
                "processing_time": processing_time,
                "processed_text": processed_text,
                "embedding_length": len(mock_embedding),
                "timestamp": datetime.now().isoformat()
            }
            
            self.metrics.completed_jobs += 1
            return result
            
        except Exception as e:
            logger.error(f"ì‘ì—… {job_data['uid']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.metrics.failed_jobs += 1
            self.metrics.errors.append(f"Job {job_data['uid']}: {str(e)}")
            
            return {
                "job_id": job_data["uid"],
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def worker_simulation(self, worker_id: int, job_queue: asyncio.Queue):
        """ê°œë³„ ì›Œì»¤ ì‹œë®¬ë ˆì´ì…˜"""
        logger.info(f"ì›Œì»¤ {worker_id} ì‹œì‘")
        
        while self.is_running:
            try:
                # íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                try:
                    job = await asyncio.wait_for(job_queue.get(), timeout=1.0)
                except asyncio.TimeoutError:
                    continue
                
                # ì‘ì—… ì²˜ë¦¬
                result = await self.simulate_job_processing(job)
                self.processed_jobs.append(result)
                
                # í ì‘ì—… ì™„ë£Œ í‘œì‹œ
                job_queue.task_done()
                
                # ì§„í–‰ ìƒí™© ë¡œê·¸ (100ê°œë§ˆë‹¤)
                if self.metrics.completed_jobs % 100 == 0:
                    elapsed = time.time() - self.metrics.start_time
                    rate = self.metrics.completed_jobs / elapsed if elapsed > 0 else 0
                    logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {self.metrics.completed_jobs}/{self.metrics.total_jobs} ({rate:.1f} jobs/sec)")
                
            except Exception as e:
                logger.error(f"ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {e}")
                await asyncio.sleep(1)
        
        logger.info(f"ì›Œì»¤ {worker_id} ì¢…ë£Œ")
    
    async def run_load_test(self, total_products: int = 30000, batch_size: int = 30, num_workers: int = 10):
        """ë©”ì¸ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info(f"ğŸš€ 30k ë§¤ë¬¼ ì²˜ë¦¬ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        logger.info(f"ğŸ“Š ì„¤ì •: ì´ {total_products:,}ê°œ ë§¤ë¬¼, ë°°ì¹˜ í¬ê¸° {batch_size}, ì›Œì»¤ {num_workers}ê°œ")
        
        self.metrics.total_jobs = total_products
        
        # ì‘ì—… í ìƒì„± 
        job_queue = asyncio.Queue(maxsize=batch_size * 5)  # í í¬ê¸° ì œí•œ
        
        # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘
        monitor_task = asyncio.create_task(self.monitor_system_resources())
        
        # ì›Œì»¤ íƒœìŠ¤í¬ë“¤ ì‹œì‘
        worker_tasks = [
            asyncio.create_task(self.worker_simulation(i, job_queue))
            for i in range(num_workers)
        ]
        
        # ë°ì´í„° ìƒì„± ë° íì— ì¶”ê°€
        logger.info("ğŸ“¦ ë§¤ë¬¼ ë°ì´í„° ìƒì„± ë° íì— ì¶”ê°€ ì¤‘...")
        
        total_batches = (total_products + batch_size - 1) // batch_size
        
        try:
            for batch_num in range(total_batches):
                if not self.is_running:
                    break
                    
                start_uid = batch_num * batch_size
                current_batch_size = min(batch_size, total_products - start_uid)
                
                # ë°°ì¹˜ ë°ì´í„° ìƒì„±
                batch_products = self.product_generator.generate_batch(start_uid, current_batch_size)
                
                # íì— ì¶”ê°€
                for product in batch_products:
                    await job_queue.put(product)
                
                # ì§„í–‰ ìƒí™© ë¡œê·¸
                if batch_num % 100 == 0:
                    logger.info(f"ë°ì´í„° ìƒì„±: {batch_num}/{total_batches} ë°°ì¹˜ ì™„ë£Œ")
                
                # íê°€ ë„ˆë¬´ ì°¨ì§€ ì•Šë„ë¡ ì ì‹œ ëŒ€ê¸°
                while job_queue.qsize() > batch_size * 3:
                    await asyncio.sleep(0.1)
            
            logger.info("ğŸ ëª¨ë“  ë°ì´í„° ìƒì„± ì™„ë£Œ, ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
            
            # ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            await job_queue.join()
            
        except Exception as e:
            logger.error(f"ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            self.metrics.errors.append(f"Main test error: {str(e)}")
        
        finally:
            # ì¢…ë£Œ ì²˜ë¦¬
            self.is_running = False
            self.metrics.end_time = time.time()
            
            # íƒœìŠ¤í¬ ì •ë¦¬
            monitor_task.cancel()
            for task in worker_tasks:
                task.cancel()
            
            # íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
            await asyncio.gather(monitor_task, *worker_tasks, return_exceptions=True)
            
            # ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°
            self._calculate_final_metrics()
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_results()
            
            # ê²°ê³¼ ì €ì¥
            await self._save_results()
    
    def _calculate_final_metrics(self):
        """ìµœì¢… ë©”íŠ¸ë¦­ ê³„ì‚°"""
        total_time = self.metrics.end_time - self.metrics.start_time
        
        if total_time > 0:
            self.metrics.jobs_per_second = self.metrics.completed_jobs / total_time
        
        if self.processed_jobs:
            processing_times = [
                job["processing_time"] 
                for job in self.processed_jobs 
                if job.get("processing_time")
            ]
            if processing_times:
                self.metrics.avg_processing_time = sum(processing_times) / len(processing_times)
    
    def _print_results(self):
        """ê²°ê³¼ ì¶œë ¥"""
        total_time = self.metrics.end_time - self.metrics.start_time
        success_rate = (self.metrics.completed_jobs / self.metrics.total_jobs * 100) if self.metrics.total_jobs > 0 else 0
        
        print("\n" + "="*60)
        print("ğŸ† 30K ë§¤ë¬¼ ì²˜ë¦¬ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("="*60)
        print(f"ğŸ“Š ì „ì²´ í†µê³„:")
        print(f"   â€¢ ì´ ì‘ì—… ìˆ˜: {self.metrics.total_jobs:,}")
        print(f"   â€¢ ì™„ë£Œëœ ì‘ì—…: {self.metrics.completed_jobs:,}")
        print(f"   â€¢ ì‹¤íŒ¨í•œ ì‘ì—…: {self.metrics.failed_jobs:,}")
        print(f"   â€¢ ì„±ê³µë¥ : {success_rate:.1f}%")
        print(f"   â€¢ ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   â€¢ ì²˜ë¦¬ ì†ë„: {self.metrics.jobs_per_second:.1f} jobs/sec")
        print(f"   â€¢ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {self.metrics.avg_processing_time:.3f}ì´ˆ")
        print()
        print(f"ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:")
        print(f"   â€¢ CPU ì‚¬ìš©ë¥ : {self.metrics.cpu_usage_percent:.1f}%")
        print(f"   â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {self.metrics.memory_usage_mb:.1f}MB")
        print(f"   â€¢ Redis ì—°ê²° ìˆ˜: {self.metrics.redis_connections_used}")
        print()
        
        if self.metrics.errors:
            print(f"âŒ ì˜¤ë¥˜ ({len(self.metrics.errors)}ê°œ):")
            for error in self.metrics.errors[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                print(f"   â€¢ {error}")
            if len(self.metrics.errors) > 5:
                print(f"   â€¢ ... ê·¸ ì™¸ {len(self.metrics.errors) - 5}ê°œ")
        else:
            print("âœ… ì˜¤ë¥˜ ì—†ìŒ")
        
        print("="*60)
    
    async def _save_results(self):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"load_test_results_{timestamp}.json"
        
        results = {
            "test_info": {
                "timestamp": datetime.now().isoformat(),
                "total_products": self.metrics.total_jobs,
                "batch_size": self.config.REDIS_BATCH_SIZE,
                "redis_max_connections": self.config.REDIS_MAX_CONNECTIONS,
                "redis_connection_timeout": self.config.REDIS_CONNECTION_TIMEOUT
            },
            "metrics": asdict(self.metrics),
            "sample_processed_jobs": self.processed_jobs[:10]  # ìƒ˜í”Œ 10ê°œë§Œ
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸï¸ 30K ì˜¤í† ë°”ì´ ë§¤ë¬¼ ì²˜ë¦¬ ë¶€í•˜ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    total_products = 30000  # ì‹¤ì œ 30k ë§¤ë¬¼
    batch_size = 30        # ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸°
    num_workers = 10       # ë™ì‹œ ì›Œì»¤ ìˆ˜
    
    # ì‚¬ìš©ì í™•ì¸
    print(f"ì„¤ì •:")
    print(f"  â€¢ ì´ ë§¤ë¬¼ ìˆ˜: {total_products:,}ê°œ")
    print(f"  â€¢ ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"  â€¢ ì›Œì»¤ ìˆ˜: {num_workers}")
    print(f"  â€¢ ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {total_products / (batch_size * 2):.0f}ë¶„")
    print()
    
    confirm = input("í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if confirm.lower() != 'y':
        print("í…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = LoadTestRunner()
    
    try:
        await runner.run_load_test(
            total_products=total_products,
            batch_size=batch_size, 
            num_workers=num_workers
        )
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 