#!/usr/bin/env python3
"""
ì œí•œëœ ë²”ìœ„ì˜ Bulk Sync ìŠ¤í¬ë¦½íŠ¸
PID < 338683404ì¸ ì œí’ˆë“¤ë§Œ ì²˜ë¦¬í•˜ì—¬ 400ê°œë¥¼ Redis Queue í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
"""

import asyncio
import logging
import time
from src.config import get_settings
from src.database.postgresql import PostgreSQLManager
from src.database.qdrant import QdrantManager, generate_product_vector_id
from src.services.text_preprocessor import ProductTextPreprocessor
from src.services.embedding_service import EmbeddingService

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class LimitedBulkSync:
    """ì œí•œëœ ë²”ìœ„ì˜ ëŒ€ëŸ‰ ë™ê¸°í™”"""
    
    def __init__(self, pid_limit: int = 338683404, batch_size: int = 50):
        self.pid_limit = pid_limit
        self.batch_size = batch_size
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.pg_manager = PostgreSQLManager()
        self.qdrant_manager = QdrantManager()
        self.preprocessor = ProductTextPreprocessor()
        self.embedding_service = EmbeddingService()
        
        # í†µê³„
        self.processed_count = 0
        self.success_count = 0
        self.error_count = 0
        self.start_time = None
        
    async def get_target_products(self) -> int:
        """ì²˜ë¦¬ ëŒ€ìƒ ì œí’ˆ ìˆ˜ í™•ì¸"""
        async with self.pg_manager.get_connection() as conn:
            result = await conn.fetchrow("""
                SELECT COUNT(*) as count
                FROM product 
                WHERE status = 1 
                AND is_conversion = false 
                AND CAST(pid AS INTEGER) < $1
            """, self.pid_limit)
            
            return result['count']
    
    async def process_batch(self, products: list) -> tuple[int, int]:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        success = 0
        errors = 0
        
        for product in products:
            try:
                # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
                processed_text = self.preprocessor.preprocess_product_data(product)
                
                # ì„ë² ë”© ìƒì„±
                embeddings = await self.embedding_service.create_embeddings_async([processed_text])
                embedding = embeddings[0] if embeddings else None
                
                if embedding is None:
                    raise Exception("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                
                # ë²¡í„° ID ìƒì„± (ìƒˆë¡œìš´ UUID ë¡œì§)
                vector_id = generate_product_vector_id(product['pid'], 'bunjang')
                
                # Qdrantì— ì €ì¥
                await self.qdrant_manager.upsert_vector_async(
                    vector_id=vector_id,
                    vector=embedding,
                    metadata={
                        'pid': product['pid'],
                        'title': product['title'],
                        'price': float(product['price']) if product['price'] else 0.0,
                        'year': product['year'] if product['year'] else 0,
                        'provider': 'bunjang'
                    }
                )
                
                # PostgreSQL ì—…ë°ì´íŠ¸
                async with self.pg_manager.get_connection() as conn:
                    await conn.execute("""
                        UPDATE product 
                        SET is_conversion = true 
                        WHERE pid = $1
                    """, product['pid'])
                
                success += 1
                logger.debug(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {product['pid']} - {product['title'][:50]}")
                
            except Exception as e:
                errors += 1
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨ {product['pid']}: {e}")
        
        return success, errors
    
    async def run_sync(self):
        """ë™ê¸°í™” ì‹¤í–‰"""
        logger.info("ğŸš€ ì œí•œëœ ë²”ìœ„ ëŒ€ëŸ‰ ë™ê¸°í™” ì‹œì‘")
        self.start_time = time.time()
        
        # ì²˜ë¦¬ ëŒ€ìƒ í™•ì¸
        target_count = await self.get_target_products()
        logger.info(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: {target_count:,}ê°œ ì œí’ˆ (PID < {self.pid_limit:,})")
        
        if target_count == 0:
            logger.info("âœ… ì²˜ë¦¬í•  ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            return True
        
        # ë°°ì¹˜ ì²˜ë¦¬
        offset = 0
        
        while True:
            # ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            async with self.pg_manager.get_connection() as conn:
                products = await conn.fetch("""
                    SELECT pid, title, content, price, year
                    FROM product 
                    WHERE status = 1 
                    AND is_conversion = false 
                    AND CAST(pid AS INTEGER) < $1
                    ORDER BY pid
                    LIMIT $2 OFFSET $3
                """, self.pid_limit, self.batch_size, offset)
            
            if not products:
                break
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_success, batch_errors = await self.process_batch(products)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.processed_count += len(products)
            self.success_count += batch_success
            self.error_count += batch_errors
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            elapsed = time.time() - self.start_time
            rate = self.processed_count / elapsed if elapsed > 0 else 0
            remaining = target_count - self.processed_count
            eta = remaining / rate if rate > 0 else 0
            
            logger.info(f"ğŸ“ˆ ì§„í–‰: {self.processed_count:,}/{target_count:,} ({self.processed_count/target_count*100:.1f}%) | "
                       f"ì„±ê³µ: {self.success_count:,} | ì‹¤íŒ¨: {self.error_count:,} | "
                       f"ì†ë„: {rate:.1f}/ì´ˆ | ETA: {eta/60:.1f}ë¶„")
            
            offset += self.batch_size
            
            # ì§§ì€ ëŒ€ê¸° (ì‹œìŠ¤í…œ ë¶€í•˜ ì™„í™”)
            await asyncio.sleep(0.1)
        
        # ìµœì¢… í†µê³„
        total_time = time.time() - self.start_time
        logger.info(f"ğŸ‰ ë™ê¸°í™” ì™„ë£Œ!")
        logger.info(f"  â€¢ ì²˜ë¦¬ëœ ì œí’ˆ: {self.processed_count:,}ê°œ")
        logger.info(f"  â€¢ ì„±ê³µ: {self.success_count:,}ê°œ")
        logger.info(f"  â€¢ ì‹¤íŒ¨: {self.error_count:,}ê°œ") 
        logger.info(f"  â€¢ ì„±ê³µë¥ : {(self.success_count/self.processed_count*100):.2f}%")
        logger.info(f"  â€¢ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"  â€¢ í‰ê·  ì†ë„: {self.processed_count/total_time:.2f} ì œí’ˆ/ì´ˆ")
        
        return self.error_count == 0
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.pg_manager:
            await self.pg_manager.close()
        if self.qdrant_manager:
            await self.qdrant_manager.close()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    sync = LimitedBulkSync(pid_limit=338683404, batch_size=50)
    
    try:
        success = await sync.run_sync()
        if success:
            logger.info("âœ… ì œí•œëœ ë²”ìœ„ ë™ê¸°í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            logger.warning("âš ï¸ ì¼ë¶€ ì˜¤ë¥˜ê°€ ìˆì—ˆì§€ë§Œ ë™ê¸°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"âŒ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        await sync.close()

if __name__ == "__main__":
    asyncio.run(main())