import os
import uuid
from typing import List, Dict, Any, Optional, Union, Tuple
import numpy as np
from qdrant_client import QdrantClient, AsyncQdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, Range, MatchValue
from qdrant_client.models import Record, ScoredPoint, UpdateResult, UpdateStatus

from src.api.models import QdrantDocument
from src.api.schema import DocumentCreate, DocumentUpdate, DocumentMetadata
from src.config import get_settings
from langchain_openai import OpenAIEmbeddings
from langchain_core.embeddings import Embeddings

# ìºì‹± ê´€ë ¨ import ì¶”ê°€
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore
import hashlib
import re

config = get_settings()


class QdrantService:
    """Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # Qdrant ì—°ê²° ì„¤ì •
        # host: Qdrant ì„œë²„ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
        # port: Qdrant HTTP API í¬íŠ¸
        # grpc_port: Qdrant gRPC API í¬íŠ¸
        # prefer_grpc: gRPC í”„ë¡œí† ì½œ ì‚¬ìš© ì—¬ë¶€ (ì„±ëŠ¥ì´ ë” ì¢‹ìŒ)
        # collection_name: ë²¡í„°ë¥¼ ì €ì¥í•  ì»¬ë ‰ì…˜ ì´ë¦„
        # vector_size: ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› ìˆ˜ (ì‚¬ìš©í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ ê²°ì •)
        self.host = config.QDRANT_HOST
        self.port = config.QDRANT_PORT
        self.grpc_port = config.QDRANT_GRPC_PORT
        self.prefer_grpc = config.QDRANT_PREFER_GRPC
        self.collection_name = config.QDRANT_COLLECTION
        self.vector_size = config.VECTOR_SIZE
        self.use_memory = config.QDRANT_USE_MEMORY
        
        # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            if self.use_memory:
                # ì¸ë©”ëª¨ë¦¬ ëª¨ë“œ (í…ŒìŠ¤íŠ¸/ê°œë°œìš©, ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš”)
                print("ğŸŸ¡ Qdrant ì¸ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì´ˆê¸°í™” ì¤‘...")
                self.client = QdrantClient(":memory:")
                self.async_client = AsyncQdrantClient(":memory:")
                print("âœ… Qdrant ì¸ë©”ëª¨ë¦¬ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                # ì„œë²„ ì—°ê²° ëª¨ë“œ (ìš´ì˜ìš©)
                print(f"ğŸŸ¡ Qdrant ì„œë²„ ì—°ê²° ì¤‘... ({self.host}:{self.port})")
                self.client = QdrantClient(
                    host=self.host, 
                    port=self.port,
                    grpc_port=self.grpc_port if self.prefer_grpc else None,
                    prefer_grpc=self.prefer_grpc
                )
                
                # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë„ í•¨ê»˜ ì´ˆê¸°í™”
                self.async_client = AsyncQdrantClient(
                    host=self.host, 
                    port=self.port,
                    grpc_port=self.grpc_port if self.prefer_grpc else None,
                    prefer_grpc=self.prefer_grpc
                )
                print("âœ… Qdrant ì„œë²„ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜
            print("ğŸŸ¡ ìë™ìœ¼ë¡œ ì¸ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            self.client = QdrantClient(":memory:")
            self.async_client = AsyncQdrantClient(":memory:")
            self.use_memory = True
            print("âœ… Qdrant ì¸ë©”ëª¨ë¦¬ í´ë¼ì´ì–¸íŠ¸ë¡œ ëŒ€ì²´ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ê¸°ë³¸ OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        base_embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            openai_api_key=config.OPENAI_API_KEY,
            dimensions=self.vector_size,
        )
        
        # ìºì‹± ì„¤ì • - ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
        cache_dir = "./cache/embeddings"
        os.makedirs(cache_dir, exist_ok=True)
        
        store = LocalFileStore(cache_dir)
        
        # ìºì‹œ ë°±ì—… ì„ë² ë”© ì´ˆê¸°í™”
        self.embeddings = CacheBackedEmbeddings.from_bytes_store(
            base_embeddings,
            store,
            namespace=f"{base_embeddings.model}-{self.vector_size}d"  # ëª¨ë¸ëª… + ì°¨ì›ìˆ˜ë¡œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ êµ¬ë¶„
        )
        
        print(f"ì„ë² ë”© ìºì‹œ ì„¤ì • ì™„ë£Œ: {cache_dir}")
        
        # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„± (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        try:
            self._create_collection_if_not_exists()
        except Exception as e:
            print(f"âš ï¸ ì»¬ë ‰ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì„œë¹„ìŠ¤ëŠ” ê³„ì† ë™ì‘): {e}")
    
    def _create_collection_if_not_exists(self) -> None:
        """ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±"""
        try:
            collections = self.client.get_collections().collections
            collection_names = [c.name for c in collections]
            
            if self.collection_name not in collection_names:
                self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE),
                    optimizers_config=models.OptimizersConfigDiff(
                        indexing_threshold=20000,  # ìƒ‰ì¸í™” ì„ê³„ê°’ (ì´ ìˆ˜ ì´ìƒì˜ ë²¡í„°ê°€ ì¶”ê°€ë˜ë©´ ìë™ìœ¼ë¡œ ì¸ë±ì‹±)
                    ),
                    on_disk_payload=True  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ìœ„í•´ í˜ì´ë¡œë“œë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
                )
                mode_info = "ì¸ë©”ëª¨ë¦¬" if self.use_memory else f"ì„œë²„({self.host}:{self.port})"
                print(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}'ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ({mode_info})")
            else:
                mode_info = "ì¸ë©”ëª¨ë¦¬" if self.use_memory else f"ì„œë²„({self.host}:{self.port})"
                print(f"âœ… ì»¬ë ‰ì…˜ '{self.collection_name}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ({mode_info})")
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ í™•ì¸/ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise e
    
    async def generate_embedding_text(self, document: DocumentCreate) -> str:
        """ë¬¸ì„œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì˜ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
        # ì´ë¯¸ ì„ë² ë”© í…ìŠ¤íŠ¸ê°€ ì œê³µëœ ê²½ìš°
        if document.embedding_text:
            return document.embedding_text
        
        metadata = document.metadata or DocumentMetadata()
        
        # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ì„ë² ë”© í…ìŠ¤íŠ¸ ìƒì„±
        embedding_parts = []
        
        # 1. ì œëª© (ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´)
        embedding_parts.append(f"## ì œëª©: {document.title}")
        
        # 2. í•µì‹¬ ë§¤ë¬¼ ì •ë³´ (ê³ ê°€ì¹˜ ì •ë³´ë“¤)
        vehicle_info = []
        if metadata.model_name:
            vehicle_info.append(f"ëª¨ë¸ëª…: {metadata.model_name}")
        if metadata.year:
            vehicle_info.append(f"ì—°ì‹: {metadata.year}ë…„")
        if metadata.price:
            vehicle_info.append(f"ê°€ê²©: {metadata.price:,}ì›")
        if metadata.odo:
            vehicle_info.append(f"ì£¼í–‰ê±°ë¦¬: {metadata.odo:,}km")
        if metadata.color:
            vehicle_info.append(f"ìƒ‰ìƒ: {metadata.color}")

        if vehicle_info:
            embedding_parts.append(f"### ë§¤ë¬¼ ì •ë³´:\n{' | '.join(vehicle_info)}")
        
        # 3. ìƒì„¸ ë‚´ìš© (ì„¤ëª… í…ìŠ¤íŠ¸)
        if metadata.content:
            embedding_parts.append(f"### ë§¤ë¬¼ ìƒì„¸ ì„¤ëª…:\n{metadata.content}")
        
        # 4. ì¶”ê°€ ì •ë³´ (ìˆëŠ” ê²½ìš°)
        additional_info = []
        if metadata.image_url:
            additional_info.append("ì´ë¯¸ì§€ ì²¨ë¶€ë¨")
        if metadata.last_modified_at:
            additional_info.append(f"ìµœì¢… ìˆ˜ì •: {metadata.last_modified_at}")
        
        if additional_info:
            embedding_parts.append(f"### ì¶”ê°€ ì •ë³´: {' | '.join(additional_info)}")
        
        # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ê²°í•©
        embedding_text = "\n\n".join(embedding_parts)
        
        return embedding_text

    async def insert_document(self, document: DocumentCreate, wait: bool = True) -> str:
        """ë¬¸ì„œë¥¼ Qdrantì— ì‚½ì…"""
        # Qdrant point ID ê²°ì • (DB UID ìš°ì„  ì‚¬ìš©)
        if document.metadata and document.metadata.id:
            # DB UIDê°€ ìˆìœ¼ë©´ ê·¸ê±¸ Qdrant point IDë¡œ ì‚¬ìš©
            point_id = str(document.metadata.id)
        elif document.id:
            # Document IDê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            point_id = document.id
        else:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            point_id = str(uuid.uuid4())
            # ìƒì„±ëœ IDë¥¼ metadataì—ë„ ì €ì¥
            if document.metadata:
                document.metadata.id = point_id
            else:
                document.metadata = DocumentMetadata(id=point_id)
        
        # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±
        embedding_text = await self.generate_embedding_text(document)
        
        # ì„ë² ë”© ìƒì„±
        vector = await self.generate_embedding(embedding_text)
        
        # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        metadata_dict = document.metadata.dict(exclude_none=True) if document.metadata else {}
        
        # Qdrantì— ì  ì¶”ê°€
        await self.async_client.upsert(
            collection_name=self.collection_name,
            wait=wait,
            points=[
                PointStruct(
                    id=point_id,  # DB UID = Qdrant point ID
                    vector=vector,
                    payload={
                        "title": document.title,
                        "embedding_text": embedding_text,
                        **metadata_dict
                    }
                )
            ]
        )
        
        return point_id
    
    async def batch_insert_documents(
        self, 
        documents: List[DocumentCreate], 
        ids: Optional[List[str]] = None,
        batch_size: int = 100,
        wait: bool = True
    ) -> List[str]:
        """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì¼ê´„ì ìœ¼ë¡œ Qdrantì— ì‚½ì… (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ê¸°ëŠ¥ í¬í•¨)"""
        doc_ids = []
        points = []
        
        # ëª¨ë“  ë¬¸ì„œì˜ ì„ë² ë”© í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ìƒì„±
        embedding_texts = []
        for document in documents:
            embedding_text = await self.generate_embedding_text(document)
            embedding_texts.append(embedding_text)
        
        # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± (ì„±ëŠ¥ í–¥ìƒ)
        vectors = await self.generate_embeddings_batch(embedding_texts)
        
        for idx, document in enumerate(documents):
            # UUID í˜•ì‹ ë³´ì¥
            if document.metadata and document.metadata.id:
                point_id = convert_to_uuid_if_needed(str(document.metadata.id))
            elif document.id:
                point_id = convert_to_uuid_if_needed(document.id)
            else:
                point_id = str(uuid.uuid4())
            
            # UUID í˜•ì‹ ê²€ì¦
            if not is_valid_uuid(point_id):
                raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ UUID í˜•ì‹: {point_id}")
            
            doc_ids.append(point_id)
            
            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            metadata_dict = document.metadata.dict(exclude_none=True) if document.metadata else {}
            
            # Qdrant í¬ì¸íŠ¸ ì¤€ë¹„
            points.append(
                PointStruct(
                    id=point_id,  # DB UID = Qdrant point ID
                    vector=vectors[idx],
                    payload={
                        "title": document.title,
                        "embedding_text": embedding_texts[idx],
                        **metadata_dict
                    }
                )
            )
        
        # ì¼ê´„ ì‚½ì… (ë°°ì¹˜ í¬ê¸°ë¡œ ë¶„í• )
        if points:
            for i in range(0, len(points), batch_size):
                batch = points[i:i + batch_size]
                await self.async_client.upsert(
                    collection_name=self.collection_name,
                    wait=wait,
                    points=batch
                )
        
        return doc_ids
    
    async def delete_document(self, doc_id: str, wait: bool = True) -> Dict[str, Any]:
        """ë¬¸ì„œ IDë¡œ ë¬¸ì„œ ì‚­ì œ"""
        try:
            operation_result = await self.async_client.delete(
                collection_name=self.collection_name,
                points_selector=models.PointIdsList(
                    points=[doc_id]
                ),
                wait=wait
            )
            
            return {
                "success": True,
                "operation_id": str(operation_result.operation_id) if operation_result.operation_id else None
            }
        except Exception as e:
            print(f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"success": False}
    
    async def batch_delete_documents(self, doc_ids: List[str], wait: bool = True) -> Dict[str, Any]:
        """ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì¼ê´„ì ìœ¼ë¡œ ì‚­ì œ"""
        try:
            operation_result = await self.async_client.delete(
                collection_name=self.collection_name,
                points_selector=models.PointIdsList(
                    points=doc_ids
                ),
                wait=wait
            )
            
            return {
                "success": True,
                "operation_id": str(operation_result.operation_id) if operation_result.operation_id else None
            }
        except Exception as e:
            print(f"ë¬¸ì„œ ì¼ê´„ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"success": False}
    
    async def get_document(self, doc_id: str, with_vectors: bool = False) -> Optional[Dict[str, Any]]:
        """ë¬¸ì„œ IDë¡œ ë¬¸ì„œ ì¡°íšŒ"""
        try:
            result = await self.async_client.retrieve(
                collection_name=self.collection_name,
                ids=[doc_id],
                with_vectors=with_vectors,
                with_payload=True
            )
            
            if result and len(result) > 0:
                point = result[0]
                response = {
                    "id": point.id,
                    "content": point.payload.get("content"),
                    "metadata": {k: v for k, v in point.payload.items() if k != "content"}
                }
                
                if with_vectors:
                    response["vector"] = point.vector
                
                return response
            
            return None
        except Exception as e:
            print(f"ë¬¸ì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    async def list_documents(
        self, 
        offset: int = 0, 
        limit: int = 10,
        with_vectors: bool = False
    ) -> Tuple[List[Dict[str, Any]], int]:
        """ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ (í˜ì´ì§• ì§€ì›)"""
        try:
            # ì „ì²´ ë¬¸ì„œ ìˆ˜ ë¨¼ì € ì¡°íšŒ
            total_count = await self.count_documents()
            
            # ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
            scroll_results = await self.async_client.scroll(
                collection_name=self.collection_name,
                limit=limit,
                offset=offset,
                with_vectors=with_vectors,
                with_payload=True
            )
            
            points = scroll_results.points
            documents = []
            
            for point in points:
                doc = {
                    "id": point.id,
                    "content": point.payload.get("content"),
                    "metadata": {k: v for k, v in point.payload.items() if k != "content"}
                }
                
                if with_vectors:
                    doc["vector"] = point.vector
                
                documents.append(doc)
            
            return documents, total_count
        except Exception as e:
            print(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [], 0
    
    async def update_document(self, doc_id: str, update_data: DocumentUpdate, wait: bool = True) -> Dict[str, Any]:
        """ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ë‚´ìš© ë˜ëŠ” ë©”íƒ€ë°ì´í„°)"""
        try:
            # ê¸°ì¡´ ë¬¸ì„œ ì¡°íšŒ
            document = await self.get_document(doc_id)
            if not document:
                return {"success": False}
            
            update_operations = []
            
            # ë‚´ìš© ì—…ë°ì´íŠ¸ê°€ ìˆë‹¤ë©´ ì„ë² ë”©ë„ ì¬ìƒì„±
            if update_data.content is not None:
                # ìƒˆ ì„ë² ë”© ìƒì„±
                vector = await self.generate_embedding(update_data.content)
                
                # ë²¡í„° ì—…ë°ì´íŠ¸
                await self.async_client.update_vectors(
                    collection_name=self.collection_name,
                    points=[
                        models.PointVectors(
                            id=doc_id,
                            vector=vector
                        )
                    ],
                    wait=wait
                )
                
                # ë‚´ìš© ì—…ë°ì´íŠ¸ ì‘ì—… ì¶”ê°€
                update_operations.append(
                    models.SetPayload(
                        payload={"content": update_data.content},
                        points=[doc_id]
                    )
                )
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ê°€ ìˆë‹¤ë©´ ì ìš©
            if update_data.metadata:
                metadata_dict = update_data.metadata.dict(exclude_none=True)
                
                if metadata_dict:
                    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì‘ì—… ì¶”ê°€
                    update_operations.append(
                        models.SetPayload(
                            payload=metadata_dict,
                            points=[doc_id]
                        )
                    )
            
            # ì—…ë°ì´íŠ¸ ì‹œê°„ ì¶”ê°€
            from datetime import datetime
            update_operations.append(
                models.SetPayload(
                    payload={"updated_at": datetime.now().isoformat()},
                    points=[doc_id]
                )
            )
            
            # ëª¨ë“  í˜ì´ë¡œë“œ ì—…ë°ì´íŠ¸ ì‘ì—… ìˆ˜í–‰
            if update_operations:
                last_operation = None
                for operation in update_operations:
                    operation_result = await self.async_client.set_payload(
                        collection_name=self.collection_name,
                        payload=operation.payload,
                        points=operation.points,
                        wait=wait
                    )
                    last_operation = operation_result
                
                return {
                    "success": True,
                    "operation_id": str(last_operation.operation_id) if last_operation and last_operation.operation_id else None
                }
            
            return {"success": True}
        except Exception as e:
            print(f"ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"success": False}
    
    async def search_documents_by_text(
        self, 
        query: str, 
        limit: int = 5,
        filter: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì—ì„œ ì„ë² ë”© ìƒì„±
            query_vector = await self.generate_embedding(query)
            
            # í•„í„° ë³€í™˜ (ì œê³µëœ ê²½ìš°)
            query_filter = self._convert_filter_dict_to_model(filter) if filter else None
            
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            search_results = await self.async_client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                query_filter=query_filter,
                with_payload=True,
                score_threshold=0.5  # ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ (ì´ë³´ë‹¤ ë‚®ì€ ê²°ê³¼ëŠ” ì œì™¸)
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            results = []
            for point in search_results:
                results.append({
                    "id": point.id,
                    "content": point.payload.get("content"),
                    "score": point.score,
                    "metadata": {k: v for k, v in point.payload.items() if k != "content"}
                })
            
            return results
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    async def search_documents_by_vector(
        self, 
        query_vector: List[float], 
        limit: int = 5,
        filter: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """ë²¡í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            # í•„í„° ë³€í™˜ (ì œê³µëœ ê²½ìš°)
            query_filter = self._convert_filter_dict_to_model(filter) if filter else None
            
            # ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
            search_results = await self.async_client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                query_filter=query_filter,
                with_payload=True,
                score_threshold=0.5  # ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’ (ì´ë³´ë‹¤ ë‚®ì€ ê²°ê³¼ëŠ” ì œì™¸)
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            results = []
            for point in search_results:
                results.append({
                    "id": point.id,
                    "content": point.payload.get("content"),
                    "score": point.score,
                    "metadata": {k: v for k, v in point.payload.items() if k != "content"}
                })
            
            return results
        except Exception as e:
            print(f"ë²¡í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def _convert_filter_dict_to_model(self, filter_dict: Dict[str, Any]) -> Filter:
        """ì‚¬ì „ í˜•ì‹ì˜ í•„í„°ë¥¼ Qdrant Filter ëª¨ë¸ë¡œ ë³€í™˜"""
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ í•„í„° ë³€í™˜ êµ¬í˜„
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ì¡°ê±´ ë° ì¤‘ì²© í•„í„°ë¥¼ ì§€ì›í•  ìˆ˜ ìˆìŒ
        must_conditions = []
        should_conditions = []
        must_not_conditions = []
        
        # í•„í„°ê°€ ë” ë³µì¡í•œ êµ¬ì¡°ì¸ ê²½ìš° ë” ì •êµí•œ ë³€í™˜ ë¡œì§ì´ í•„ìš”í•©ë‹ˆë‹¤.
        # í˜„ì¬ êµ¬í˜„ì€ ê¸°ë³¸ì ì¸ í•„ë“œ ì¡°ê±´ë§Œ ì§€ì›í•©ë‹ˆë‹¤.
        
        if "must" in filter_dict:
            for condition in filter_dict["must"]:
                field_condition = self._create_field_condition(condition)
                if field_condition:
                    must_conditions.append(field_condition)
        
        if "should" in filter_dict:
            for condition in filter_dict["should"]:
                field_condition = self._create_field_condition(condition)
                if field_condition:
                    should_conditions.append(field_condition)
        
        if "must_not" in filter_dict:
            for condition in filter_dict["must_not"]:
                field_condition = self._create_field_condition(condition)
                if field_condition:
                    must_not_conditions.append(field_condition)
        
        return Filter(
            must=must_conditions if must_conditions else None,
            should=should_conditions if should_conditions else None,
            must_not=must_not_conditions if must_not_conditions else None
        )
    
    def _create_field_condition(self, condition: Dict[str, Any]) -> Optional[FieldCondition]:
        """í•„ë“œ ì¡°ê±´ ìƒì„±"""
        if not isinstance(condition, dict) or "key" not in condition:
            return None
        
        key = condition["key"]
        
        if "match" in condition:
            return FieldCondition(
                key=key,
                match=MatchValue(value=condition["match"])
            )
        elif "range" in condition:
            range_dict = condition["range"]
            range_params = {}
            
            if "gte" in range_dict:
                range_params["gte"] = range_dict["gte"]
            if "gt" in range_dict:
                range_params["gt"] = range_dict["gt"]
            if "lte" in range_dict:
                range_params["lte"] = range_dict["lte"]
            if "lt" in range_dict:
                range_params["lt"] = range_dict["lt"]
            
            if range_params:
                return FieldCondition(
                    key=key,
                    range=Range(**range_params)
                )
        
        return None
    
    async def count_documents(self) -> int:
        """ì»¬ë ‰ì…˜ ë‚´ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
        try:
            collection_info = await self.async_client.get_collection(self.collection_name)
            return collection_info.vectors_count
        except Exception as e:
            print(f"ë¬¸ì„œ ìˆ˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return 0
    
    async def get_collection_info(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            collection_info = await self.async_client.get_collection(self.collection_name)
            return {
                "name": collection_info.name,
                "status": collection_info.status,
                "vectors_count": collection_info.vectors_count,
                "segments_count": collection_info.segments_count,
                "config": {
                    "vector_size": collection_info.config.params.vectors.size,
                    "distance": collection_info.config.params.vectors.distance,
                    "on_disk": collection_info.config.params.on_disk_payload
                }
            }
        except Exception as e:
            print(f"ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}

    async def generate_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì„ë² ë”© ë²¡í„° ìƒì„± (ìºì‹± ì§€ì›)"""
        try:
            # LangChain CacheBackedEmbeddingsë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ìºì‹±
            embedding_vector = await self.embeddings.aembed_query(text)
            
            # ë²¡í„° í¬ê¸° ê²€ì¦
            if len(embedding_vector) != self.vector_size:
                raise ValueError(f"ì„ë² ë”© ë²¡í„° í¬ê¸°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {self.vector_size}, ì‹¤ì œ: {len(embedding_vector)}")
            
            return embedding_vector
            
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [0.0] * self.vector_size
    
    async def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì—ì„œ ì„ë² ë”© ë²¡í„° ì¼ê´„ ìƒì„± (ìºì‹± ì§€ì›)"""
        try:
            # LangChain CacheBackedEmbeddingsì˜ ë°°ì¹˜ ë©”ì„œë“œ ì‚¬ìš©
            embedding_vectors = await self.embeddings.aembed_documents(texts)
            
            # ê° ë²¡í„° í¬ê¸° ê²€ì¦
            for i, vector in enumerate(embedding_vectors):
                if len(vector) != self.vector_size:
                    print(f"ê²½ê³ : {i}ë²ˆì§¸ ì„ë² ë”© ë²¡í„° í¬ê¸°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {self.vector_size}, ì‹¤ì œ: {len(vector)}")
                    embedding_vectors[i] = [0.0] * self.vector_size
            
            return embedding_vectors
            
        except Exception as e:
            print(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [[0.0] * self.vector_size for _ in texts]

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        try:
            cache_dir = "./cache/embeddings"
            if not os.path.exists(cache_dir):
                return {"cache_files": 0, "total_size_mb": 0}
            
            files = os.listdir(cache_dir)
            total_size = sum(os.path.getsize(os.path.join(cache_dir, f)) for f in files)
            
            return {
                "cache_files": len(files),
                "total_size_mb": round(total_size / (1024 * 1024), 2),
                "cache_directory": cache_dir
            }
        except Exception as e:
            print(f"ìºì‹œ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def clear_cache(self) -> Dict[str, Any]:
        """ìºì‹œ ì‚­ì œ (í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬ìš©)"""
        try:
            cache_dir = "./cache/embeddings"
            if os.path.exists(cache_dir):
                import shutil
                shutil.rmtree(cache_dir)
                os.makedirs(cache_dir, exist_ok=True)
                return {"success": True, "message": "ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
            else:
                return {"success": True, "message": "ì‚­ì œí•  ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤."}
        except Exception as e:
            return {"success": False, "error": str(e)}


def is_valid_uuid(uuid_string: str) -> bool:
    """UUID í˜•ì‹ì´ ìœ íš¨í•œì§€ í™•ì¸"""
    uuid_pattern = re.compile(
        r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$',
        re.IGNORECASE
    )
    return bool(uuid_pattern.match(uuid_string))

def convert_to_uuid_if_needed(point_id: str) -> str:
    """í•„ìš”ì‹œ point IDë¥¼ UUID í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if is_valid_uuid(point_id):
        return point_id
    
    # ìˆ«ìì¸ ê²½ìš° UUID í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if point_id.isdigit():
        int_id = int(point_id)
        hex_str = f"{int_id:032x}"
        return f"{hex_str[:8]}-{hex_str[8:12]}-{hex_str[12:16]}-{hex_str[16:20]}-{hex_str[20:32]}"
    
    # ê·¸ ì™¸ì˜ ê²½ìš° í•´ì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ UUID í˜•ì‹ ìƒì„±
    import hashlib
    hash_bytes = hashlib.md5(point_id.encode()).hexdigest()
    return f"{hash_bytes[:8]}-{hash_bytes[8:12]}-{hash_bytes[12:16]}-{hash_bytes[16:20]}-{hash_bytes[20:32]}"


# ì‹±ê¸€í†¤ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì œê³µ
qdrant_service = QdrantService() 