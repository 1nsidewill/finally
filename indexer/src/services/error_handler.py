"""
Robust Error Handling and Logging Service

Redis Queue Workerì˜ ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬, ë¡œê¹…, ì‹¤íŒ¨ ìž‘ì—… ì¶”ì  ëª¨ë“ˆ
"""

import asyncio
import logging
import json
import traceback
import uuid
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timezone
import sys

from src.config import get_settings
from src.database.postgresql import PostgreSQLManager

logger = logging.getLogger(__name__)

class ErrorSeverity(Enum):
    """ì˜¤ë¥˜ ì‹¬ê°ë„ ë ˆë²¨"""
    LOW = "low"           # ìž¬ì‹œë„ ê°€ëŠ¥í•œ ì¼ì‹œì  ì˜¤ë¥˜
    MEDIUM = "medium"     # ë°ì´í„° ê´€ë ¨ ì˜¤ë¥˜ (ë³µêµ¬ ê°€ëŠ¥)
    HIGH = "high"         # ì‹œìŠ¤í…œ ì˜¤ë¥˜ (ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”)
    CRITICAL = "critical" # ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ìœ„í—˜

class ErrorCategory(Enum):
    """ì˜¤ë¥˜ ì¹´í…Œê³ ë¦¬"""
    DATABASE = "database"           # PostgreSQL/Qdrant ì—°ê²°/ì¿¼ë¦¬ ì˜¤ë¥˜
    NETWORK = "network"             # API í˜¸ì¶œ, ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜
    VALIDATION = "validation"       # ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜
    PROCESSING = "processing"       # ë°ì´í„° ì²˜ë¦¬/ë³€í™˜ ì˜¤ë¥˜
    AUTHENTICATION = "authentication" # API í‚¤, ì¸ì¦ ì˜¤ë¥˜
    RATE_LIMIT = "rate_limit"       # API ì†ë„ ì œí•œ
    UNKNOWN = "unknown"             # ë¶„ë¥˜ë˜ì§€ ì•Šì€ ì˜¤ë¥˜

@dataclass
class ErrorContext:
    """ì˜¤ë¥˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´"""
    job_id: str
    job_type: str
    product_id: str
    operation_step: str  # ì–´ë–¤ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
    additional_data: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.additional_data is None:
            self.additional_data = {}

@dataclass
class FailedOperation:
    """ì‹¤íŒ¨í•œ ìž‘ì—… ê¸°ë¡"""
    id: str
    job_id: str
    job_type: str
    product_id: str
    error_category: ErrorCategory
    error_severity: ErrorSeverity
    error_message: str
    error_details: str
    operation_step: str
    retry_count: int = 0
    max_retries: int = 3
    created_at: datetime = None
    last_retry_at: datetime = None
    resolved_at: datetime = None
    additional_data: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now(timezone.utc)
        if self.additional_data is None:
            self.additional_data = {}

class ErrorHandler:
    """ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.settings = get_settings()
        self.postgresql_manager = None
        
        # ì˜¤ë¥˜ í†µê³„
        self.error_stats = {
            'total_errors': 0,
            'by_category': {cat.value: 0 for cat in ErrorCategory},
            'by_severity': {sev.value: 0 for sev in ErrorSeverity},
            'retry_success_count': 0,
            'permanent_failures': 0,
        }
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
    
    def _setup_logging(self):
        """êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •"""
        # JSON ë¡œê±° ìƒì„±
        self.error_logger = logging.getLogger('indexer.errors')
        self.error_logger.setLevel(logging.ERROR)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì˜¤ë¥˜ ì „ìš©)
        error_handler = logging.FileHandler('logs/errors.log')
        error_handler.setLevel(logging.ERROR)
        
        # JSON í¬ë§·í„°
        json_formatter = logging.Formatter(
            '{"timestamp": "%(asctime)s", "level": "%(levelname)s", '
            '"logger": "%(name)s", "message": %(message)s}'
        )
        error_handler.setFormatter(json_formatter)
        
        self.error_logger.addHandler(error_handler)
        
        # ì„±ëŠ¥ ë¡œê±°
        self.perf_logger = logging.getLogger('indexer.performance')
        perf_handler = logging.FileHandler('logs/performance.log')
        perf_handler.setFormatter(json_formatter)
        self.perf_logger.addHandler(perf_handler)
    
    async def initialize(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        try:
            # PostgreSQLManagerê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            if self.postgresql_manager is None:
                self.postgresql_manager = PostgreSQLManager()
                # PostgreSQLì€ lazy loadingì´ë¯€ë¡œ pool ìƒì„± í…ŒìŠ¤íŠ¸
                await self.postgresql_manager.get_pool()
            
            # failed_operations í…Œì´ë¸” ìƒì„± (ì¡´ìž¬í•˜ì§€ ì•Šìœ¼ë©´)
            await self._ensure_failed_operations_table()
            
            logger.info("âœ… ErrorHandler ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ErrorHandler ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.postgresql_manager:
            await self.postgresql_manager.close()
        logger.info("ðŸ”¹ ErrorHandler ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    
    async def _ensure_failed_operations_table(self):
        """failed_operations í…Œì´ë¸” ìƒì„± - failure_handler.pyì™€ í˜¸í™˜ë˜ëŠ” ìŠ¤í‚¤ë§ˆ"""
        try:
            async with self.postgresql_manager.get_connection() as conn:
                create_table_sql = """
                    CREATE TABLE IF NOT EXISTS failed_operations (
                        id SERIAL PRIMARY KEY,
                        operation_type VARCHAR(50) NOT NULL,
                        product_uid INTEGER NOT NULL,
                        error_message TEXT NOT NULL,
                        error_details JSONB,
                        retry_count INTEGER DEFAULT 0,
                        max_retries INTEGER DEFAULT 3,
                        next_retry_at TIMESTAMP WITH TIME ZONE,
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        last_attempted_at TIMESTAMP WITH TIME ZONE,
                        resolved_at TIMESTAMP WITH TIME ZONE
                    );
                    
                    CREATE INDEX IF NOT EXISTS idx_failed_ops_product_uid ON failed_operations(product_uid);
                    CREATE INDEX IF NOT EXISTS idx_failed_ops_operation_type ON failed_operations(operation_type);
                    CREATE INDEX IF NOT EXISTS idx_failed_ops_created_at ON failed_operations(created_at);
                    CREATE INDEX IF NOT EXISTS idx_failed_ops_retry ON failed_operations(retry_count, next_retry_at);
                """
                
                await conn.execute(create_table_sql)
                logger.debug("ðŸ”§ failed_operations í…Œì´ë¸” í™•ì¸/ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ failed_operations í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def handle_error(self, 
                          exception: Exception, 
                          context: ErrorContext,
                          auto_categorize: bool = True) -> FailedOperation:
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë° ê¸°ë¡"""
        try:
            # ì˜¤ë¥˜ ë¶„ë¥˜
            category, severity = self._categorize_error(exception) if auto_categorize else (ErrorCategory.UNKNOWN, ErrorSeverity.MEDIUM)
            
            # ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´ ìˆ˜ì§‘
            error_details = self._extract_error_details(exception)
            
            # FailedOperation ê°ì²´ ìƒì„±
            failed_op = FailedOperation(
                id=str(uuid.uuid4()),
                job_id=context.job_id,
                job_type=context.job_type,
                product_id=context.product_id,
                error_category=category,
                error_severity=severity,
                error_message=str(exception),
                error_details=error_details,
                operation_step=context.operation_step,
                additional_data=context.additional_data
            )
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡
            await self._record_failed_operation(failed_op)
            
            # êµ¬ì¡°í™”ëœ ë¡œê¹…
            await self._log_error(failed_op, exception)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_error_stats(category, severity)
            
            logger.error(f"âŒ ì˜¤ë¥˜ ì²˜ë¦¬ ì™„ë£Œ: {context.job_id} - {category.value}({severity.value})")
            
            return failed_op
            
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
            logger.critical(f"ðŸš¨ ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            traceback.print_exc()
            
            # ìµœì†Œí•œì˜ ê¸°ë³¸ ê°ì²´ ë°˜í™˜
            return FailedOperation(
                id=str(uuid.uuid4()),
                job_id=context.job_id,
                job_type=context.job_type,
                product_id=context.product_id,
                error_category=ErrorCategory.UNKNOWN,
                error_severity=ErrorSeverity.HIGH,
                error_message=str(exception),
                error_details="ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ",
                operation_step=context.operation_step
            )
    
    def _categorize_error(self, exception: Exception) -> tuple[ErrorCategory, ErrorSeverity]:
        """ì˜¤ë¥˜ ìžë™ ë¶„ë¥˜"""
        error_msg = str(exception).lower()
        error_type = type(exception).__name__
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì˜¤ë¥˜
        if any(keyword in error_msg for keyword in ['connection', 'database', 'postgresql', 'qdrant', 'sql']):
            return ErrorCategory.DATABASE, ErrorSeverity.HIGH
        
        # ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì˜¤ë¥˜
        if any(keyword in error_msg for keyword in ['network', 'timeout', 'connection refused', 'dns']):
            return ErrorCategory.NETWORK, ErrorSeverity.MEDIUM
        
        # ì¸ì¦ ê´€ë ¨ ì˜¤ë¥˜
        if any(keyword in error_msg for keyword in ['api key', 'authentication', 'unauthorized', 'forbidden']):
            return ErrorCategory.AUTHENTICATION, ErrorSeverity.HIGH
        
        # ì†ë„ ì œí•œ ì˜¤ë¥˜
        if any(keyword in error_msg for keyword in ['rate limit', 'too many requests', 'quota']):
            return ErrorCategory.RATE_LIMIT, ErrorSeverity.LOW
        
        # ë°ì´í„° ê²€ì¦ ì˜¤ë¥˜
        if any(keyword in error_msg for keyword in ['validation', 'invalid', 'missing', 'required']):
            return ErrorCategory.VALIDATION, ErrorSeverity.MEDIUM
        
        # íƒ€ìž…ë³„ ë¶„ë¥˜
        if error_type in ['ValueError', 'TypeError', 'KeyError']:
            return ErrorCategory.VALIDATION, ErrorSeverity.MEDIUM
        elif error_type in ['ConnectionError', 'TimeoutError']:
            return ErrorCategory.NETWORK, ErrorSeverity.MEDIUM
        else:
            return ErrorCategory.UNKNOWN, ErrorSeverity.MEDIUM
    
    def _extract_error_details(self, exception: Exception) -> str:
        """ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ"""
        details = {
            'exception_type': type(exception).__name__,
            'exception_args': exception.args,
            'traceback': traceback.format_exc(),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }
        
        # íŠ¹ì • ì˜ˆì™¸ íƒ€ìž…ë³„ ì¶”ê°€ ì •ë³´
        if hasattr(exception, 'response'):
            details['http_status'] = getattr(exception.response, 'status_code', None)
            details['http_response'] = getattr(exception.response, 'text', None)
        
        return json.dumps(details, ensure_ascii=False, indent=2)
    
    async def _record_failed_operation(self, failed_op: FailedOperation):
        """failed_operations í…Œì´ë¸”ì— ê¸°ë¡"""
        try:
            conn = await self.postgresql_manager.get_connection()
            
            insert_sql = """
                INSERT INTO failed_operations (
                    id, job_id, job_type, product_id, error_category, error_severity,
                    error_message, error_details, operation_step, retry_count, max_retries,
                    created_at, additional_data
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
            """
            
            await conn.execute(
                insert_sql,
                failed_op.id,
                failed_op.job_id,
                failed_op.job_type,
                failed_op.product_id,
                failed_op.error_category.value,
                failed_op.error_severity.value,
                failed_op.error_message,
                failed_op.error_details,
                failed_op.operation_step,
                failed_op.retry_count,
                failed_op.max_retries,
                failed_op.created_at,
                json.dumps(failed_op.additional_data)
            )
            
            logger.debug(f"ðŸ“ ì‹¤íŒ¨ ìž‘ì—… ê¸°ë¡ ì™„ë£Œ: {failed_op.id}")
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤íŒ¨ ìž‘ì—… ê¸°ë¡ ì‹¤íŒ¨: {e}")
            # ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë¡ ì‹¤íŒ¨í•´ë„ ì²˜ë¦¬ëŠ” ê³„ì†
    
    async def _log_error(self, failed_op: FailedOperation, exception: Exception):
        """êµ¬ì¡°í™”ëœ ì˜¤ë¥˜ ë¡œê¹…"""
        log_data = {
            'failed_operation_id': failed_op.id,
            'job_id': failed_op.job_id,
            'job_type': failed_op.job_type,
            'product_id': failed_op.product_id,
            'error_category': failed_op.error_category.value,
            'error_severity': failed_op.error_severity.value,
            'error_message': failed_op.error_message,
            'operation_step': failed_op.operation_step,
            'retry_count': failed_op.retry_count,
            'exception_type': type(exception).__name__,
            'timestamp': failed_op.created_at.isoformat(),
            'additional_data': failed_op.additional_data
        }
        
        # JSON ë¡œê·¸ ê¸°ë¡
        self.error_logger.error(json.dumps(log_data, ensure_ascii=False))
        
        # ì‹¬ê°ë„ë³„ ì¶”ê°€ ë¡œê¹…
        if failed_op.error_severity in [ErrorSeverity.HIGH, ErrorSeverity.CRITICAL]:
            logger.critical(f"ðŸš¨ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {failed_op.job_id} - {failed_op.error_message}")
    
    def _update_error_stats(self, category: ErrorCategory, severity: ErrorSeverity):
        """ì˜¤ë¥˜ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.error_stats['total_errors'] += 1
        self.error_stats['by_category'][category.value] += 1
        self.error_stats['by_severity'][severity.value] += 1
    
    async def retry_failed_operation(self, failed_operation_id: str) -> bool:
        """ì‹¤íŒ¨í•œ ìž‘ì—… ìž¬ì‹œë„"""
        try:
            conn = await self.postgresql_manager.get_connection()
            
            # ì‹¤íŒ¨í•œ ìž‘ì—… ì¡°íšŒ
            select_sql = """
                SELECT * FROM failed_operations 
                WHERE id = $1 AND resolved_at IS NULL
            """
            result = await conn.fetch(select_sql, failed_operation_id)
            
            if not result:
                logger.warning(f"âš ï¸ ìž¬ì‹œë„í•  ì‹¤íŒ¨ ìž‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {failed_operation_id}")
                return False
            
            failed_op_data = result[0]
            
            # ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜ í™•ì¸
            if failed_op_data['retry_count'] >= failed_op_data['max_retries']:
                logger.warning(f"âš ï¸ ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {failed_operation_id}")
                await self._mark_permanent_failure(failed_operation_id)
                return False
            
            # ìž¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
            update_sql = """
                UPDATE failed_operations 
                SET retry_count = retry_count + 1, last_retry_at = NOW()
                WHERE id = $1
            """
            await conn.execute(update_sql, failed_operation_id)
            
            logger.info(f"ðŸ”„ ì‹¤íŒ¨ ìž‘ì—… ìž¬ì‹œë„ ì¤€ë¹„: {failed_operation_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ìž¬ì‹œë„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def _mark_permanent_failure(self, failed_operation_id: str):
        """ì˜êµ¬ ì‹¤íŒ¨ë¡œ í‘œì‹œ"""
        try:
            conn = await self.postgresql_manager.get_connection()
            
            update_sql = """
                UPDATE failed_operations 
                SET resolved_at = NOW()
                WHERE id = $1
            """
            await conn.execute(update_sql, failed_operation_id)
            
            self.error_stats['permanent_failures'] += 1
            logger.warning(f"âš ï¸ ì˜êµ¬ ì‹¤íŒ¨ë¡œ í‘œì‹œ: {failed_operation_id}")
            
        except Exception as e:
            logger.error(f"âŒ ì˜êµ¬ ì‹¤íŒ¨ í‘œì‹œ ì‹¤íŒ¨: {e}")
    
    async def mark_resolved(self, failed_operation_id: str):
        """ì‹¤íŒ¨ ìž‘ì—…ì„ í•´ê²°ë¨ìœ¼ë¡œ í‘œì‹œ"""
        try:
            conn = await self.postgresql_manager.get_connection()
            
            update_sql = """
                UPDATE failed_operations 
                SET resolved_at = NOW()
                WHERE id = $1
            """
            await conn.execute(update_sql, failed_operation_id)
            
            self.error_stats['retry_success_count'] += 1
            logger.info(f"âœ… ì‹¤íŒ¨ ìž‘ì—… í•´ê²° ì™„ë£Œ: {failed_operation_id}")
            
        except Exception as e:
            logger.error(f"âŒ í•´ê²° í‘œì‹œ ì‹¤íŒ¨: {e}")
    
    async def get_failed_operations(self, 
                                   limit: int = 100,
                                   category: Optional[ErrorCategory] = None,
                                   severity: Optional[ErrorSeverity] = None,
                                   unresolved_only: bool = True) -> List[Dict[str, Any]]:
        """ì‹¤íŒ¨í•œ ìž‘ì—… ëª©ë¡ ì¡°íšŒ"""
        try:
            conn = await self.postgresql_manager.get_connection()
            
            conditions = []
            params = []
            param_counter = 1
            
            if unresolved_only:
                conditions.append("resolved_at IS NULL")
            
            if category:
                conditions.append(f"error_category = ${param_counter}")
                params.append(category.value)
                param_counter += 1
            
            if severity:
                conditions.append(f"error_severity = ${param_counter}")
                params.append(severity.value)
                param_counter += 1
            
            where_clause = f"WHERE {' AND '.join(conditions)}" if conditions else ""
            
            select_sql = f"""
                SELECT * FROM failed_operations 
                {where_clause}
                ORDER BY created_at DESC 
                LIMIT ${param_counter}
            """
            params.append(limit)
            
            results = await conn.fetch(select_sql, *params)
            return [dict(row) for row in results]
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤íŒ¨ ìž‘ì—… ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_error_stats(self) -> Dict[str, Any]:
        """ì˜¤ë¥˜ í†µê³„ ë°˜í™˜"""
        total = self.error_stats['total_errors']
        
        return {
            **self.error_stats,
            'error_rate_by_category': {
                cat: (count / total * 100) if total > 0 else 0
                for cat, count in self.error_stats['by_category'].items()
            },
            'retry_success_rate': (
                self.error_stats['retry_success_count'] / total * 100
                if total > 0 else 0
            )
        }
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        for key in self.error_stats:
            if isinstance(self.error_stats[key], dict):
                for subkey in self.error_stats[key]:
                    self.error_stats[key][subkey] = 0
            else:
                self.error_stats[key] = 0 