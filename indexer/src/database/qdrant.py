# src/database/qdrant.py
import os
import asyncio
from typing import List, Dict, Any, Optional, AsyncGenerator
import logging
from contextlib import asynccontextmanager
import uuid
from qdrant_client import QdrantClient, AsyncQdrantClient
from qdrant_client.http import models
from qdrant_client.http.models import Distance, VectorParams, PointStruct, Filter
from qdrant_client.models import Record, ScoredPoint, UpdateResult
from langchain_openai import OpenAIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore
from src.config import get_settings
from ..monitoring.metrics import MetricsCollector

logger = logging.getLogger(__name__)

def ensure_valid_uuid(id_value: Any) -> str:
    """ì •ìˆ˜ë‚˜ ë¬¸ìì—´ IDë¥¼ ìœ íš¨í•œ UUID í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (Deprecated)"""
    # logger.warning("ensure_valid_uuidëŠ” deprecated. generate_product_vector_id ì‚¬ìš© ê¶Œì¥")  # ì„ì‹œë¡œ ì£¼ì„ ì²˜ë¦¬
    try:
        # ì´ë¯¸ ìœ íš¨í•œ UUIDì¸ì§€ í™•ì¸
        if isinstance(id_value, str):
            try:
                uuid.UUID(id_value)
                return id_value
            except ValueError:
                pass
        
        # ì •ìˆ˜ë‚˜ ë¬¸ìì—´ì„ UUIDë¡œ ë³€í™˜
        if isinstance(id_value, (int, str)):
            # ì •ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  UUID ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‚¬ìš©
            id_str = str(id_value)
            namespace = uuid.NAMESPACE_DNS
            generated_uuid = uuid.uuid5(namespace, id_str)
            return str(generated_uuid)
        
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return str(uuid.uuid4())
        
    except Exception as e:
        logger.warning(f"UUID ë³€í™˜ ì‹¤íŒ¨: {id_value} -> {e}, ëœë¤ UUID ìƒì„±")
        return str(uuid.uuid4())

def generate_product_vector_id(uid: str, provider: str = "bunjang") -> str:
    """product.uid + providerë¡œ ê³ ìœ í•œ ë²¡í„° ID ìƒì„±
    
    Args:
        uid: ì œí’ˆì˜ ê³ ìœ  ì‹ë³„ì (ì˜ˆ: 'bunmall_1234567')
        provider: í”Œë«í¼/ì œê³µì ì •ë³´ (ì˜ˆ: 'bunjang', 'joongonara')
    
    Returns:
        str: UUID v5 ê¸°ë°˜ ê³ ìœ  ë²¡í„° ID
    
    Examples:
        >>> generate_product_vector_id("bunmall_1234567", "bunjang")
        "550e8400-e29b-41d4-a716-446655440001"
    """
    try:
        # provider:uid í˜•íƒœë¡œ ì¡°í•©
        combined_id = f"{provider}:{uid}"
        
        # UUID v5ë¡œ ê²°ì •ë¡ ì  ìƒì„± (ê°™ì€ ì…ë ¥ = ê°™ì€ ì¶œë ¥)
        namespace = uuid.NAMESPACE_DNS
        generated_uuid = uuid.uuid5(namespace, combined_id)
        
        logger.debug(f"ë²¡í„° ID ìƒì„±: {combined_id} -> {generated_uuid}")
        return str(generated_uuid)
        
    except Exception as e:
        logger.error(f"ë²¡í„° ID ìƒì„± ì‹¤íŒ¨: uid={uid}, provider={provider} -> {e}")
        # ì‹¤íŒ¨ ì‹œ ëœë¤ UUID ìƒì„±
        fallback_uuid = str(uuid.uuid4())
        logger.warning(f"Fallback UUID ì‚¬ìš©: {fallback_uuid}")
        return fallback_uuid

class QdrantManager:
    """Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ê´€ë¦¬ì"""
    
    def __init__(self):
        self.config = get_settings()
        self._client: Optional[QdrantClient] = None
        self._async_client: Optional[AsyncQdrantClient] = None
        self._embeddings: Optional[CacheBackedEmbeddings] = None
        self._client_lock = asyncio.Lock()
        
        # Qdrant ì„¤ì •
        self.host = self.config.QDRANT_HOST
        self.port = self.config.QDRANT_PORT
        self.grpc_port = self.config.QDRANT_GRPC_PORT
        self.prefer_grpc = self.config.QDRANT_PREFER_GRPC
        self.collection_name = self.config.QDRANT_COLLECTION
        self.vector_size = self.config.VECTOR_SIZE
    
    def get_sync_client(self) -> QdrantClient:
        """ë™ê¸° Qdrant í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
        if self._client is None:
            try:
                self._client = QdrantClient(
                    host=self.host,
                    port=self.port,
                    grpc_port=self.grpc_port if self.prefer_grpc else None,
                    prefer_grpc=self.prefer_grpc
                )
                logger.info(f"Qdrant ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ: {self.host}:{self.port}")
            except Exception as e:
                logger.error(f"Qdrant ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
                raise
        return self._client
    
    async def get_async_client(self) -> AsyncQdrantClient:
        """ë¹„ë™ê¸° Qdrant í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
        if self._async_client is None:
            async with self._client_lock:
                if self._async_client is None:
                    try:
                        self._async_client = AsyncQdrantClient(
                            host=self.host,
                            port=self.port,
                            grpc_port=self.grpc_port if self.prefer_grpc else None,
                            prefer_grpc=self.prefer_grpc
                        )
                        logger.info(f"Qdrant ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ: {self.host}:{self.port}")
                    except Exception as e:
                        logger.error(f"Qdrant ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
                        raise
        return self._async_client
    
    def get_embeddings(self) -> CacheBackedEmbeddings:
        """OpenAI ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (ìºì‹± í¬í•¨)"""
        if self._embeddings is None:
            try:
                # ê¸°ë³¸ OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
                base_embeddings = OpenAIEmbeddings(
                    model="text-embedding-3-large",
                    openai_api_key=self.config.OPENAI_API_KEY,
                    dimensions=self.vector_size,
                )
                
                # ìºì‹± ì„¤ì •
                cache_dir = "./cache/embeddings"
                os.makedirs(cache_dir, exist_ok=True)
                store = LocalFileStore(cache_dir)
                
                # ìºì‹œ ë°±ì—… ì„ë² ë”© ì´ˆê¸°í™”
                self._embeddings = CacheBackedEmbeddings.from_bytes_store(
                    base_embeddings,
                    store,
                    namespace=f"{base_embeddings.model}-{self.vector_size}d"
                )
                
                logger.info(f"ì„ë² ë”© ìºì‹œ ì„¤ì • ì™„ë£Œ: {cache_dir}")
            except Exception as e:
                logger.error(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise
        return self._embeddings
    
    async def create_collection_if_not_exists(self) -> bool:
        """ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„± (ìµœì í™” ì„¤ì • í¬í•¨)"""
        try:
            client = self.get_sync_client()
            collections = client.get_collections().collections
            collection_names = [c.name for c in collections]
            
            if self.collection_name not in collection_names:
                client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(
                        size=self.vector_size,
                        distance=Distance.COSINE
                    ),
                    # ğŸš€ Storage Optimization ì„¤ì •
                    optimizers_config=models.OptimizersConfigDiff(
                        # ì¸ë±ì‹± ì„ê³„ê°’: 20K í¬ì¸íŠ¸ë¶€í„° ì¸ë±ì‹± ì‹œì‘
                        indexing_threshold=20000,
                        # ë©”ëª¨ë¦¬ ë§¤í•‘ ì„ê³„ê°’: 50K í¬ì¸íŠ¸ë¶€í„° ë©”ëª¨ë¦¬ ë§¤í•‘ ì‚¬ìš©
                        memmap_threshold=50000,
                        # ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°: 200K í¬ì¸íŠ¸
                        max_segment_size=200000,
                        # ìµœëŒ€ ìµœì í™” ìŠ¤ë ˆë“œ ìˆ˜
                        max_optimization_threads=2,
                        # ì‚­ì œëœ ë²¡í„° ì •ë¦¬ ì„ê³„ê°’ (70%)
                        deleted_threshold=0.7,
                        # ë²¡í„° ì••ì¶• í™œì„±í™”
                        vacuum_min_vector_number=1000,
                        # ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
                        default_segment_number=2
                    ),
                    # ğŸ—„ï¸ ë””ìŠ¤í¬ ì €ì¥ ìµœì í™”
                    on_disk_payload=True,  # payloadë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
                    # ğŸ”§ HNSW ì¸ë±ìŠ¤ ìµœì í™” ì„¤ì •
                    hnsw_config=models.HnswConfigDiff(
                        m=16,  # ì—°ê²° ìˆ˜ (ê¸°ë³¸ê°’, ë©”ëª¨ë¦¬ vs ì •í™•ë„ ê· í˜•)
                        ef_construct=100,  # ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œ íƒìƒ‰ ê¹Šì´
                        full_scan_threshold=10000,  # ì „ì²´ ìŠ¤ìº” ì„ê³„ê°’
                        max_indexing_threads=2,  # ì¸ë±ì‹± ìŠ¤ë ˆë“œ ìˆ˜
                        on_disk=False,  # ì¸ë±ìŠ¤ëŠ” ë©”ëª¨ë¦¬ì— ìœ ì§€ (ì„±ëŠ¥)
                        payload_m=16  # payloadì™€ ì—°ê²°ëœ ë§í¬ ìˆ˜
                    ),
                    # ğŸ”„ Quantization ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
                    quantization_config=models.ScalarQuantization(
                        scalar=models.ScalarQuantizationConfig(
                            type=models.ScalarType.INT8,  # 8ë¹„íŠ¸ ì–‘ìí™”
                            quantile=0.99,  # 99% ë¶„ìœ„ìˆ˜ ì‚¬ìš©
                            always_ram=True  # ì–‘ìí™”ëœ ë²¡í„°ëŠ” RAMì— ìœ ì§€
                        )
                    ),
                    # ğŸ§¹ WAL (Write-Ahead Log) ì„¤ì •
                    wal_config=models.WalConfigDiff(
                        wal_capacity_mb=32,  # WAL ìš©ëŸ‰ 32MB
                        wal_segments_ahead=0  # ë¯¸ë¦¬ ìƒì„±í•  WAL ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜
                    )
                )
                logger.info(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ìµœì í™” ì„¤ì •ê³¼ í•¨ê»˜ ìƒì„± ì™„ë£Œ")
                logger.info("ğŸš€ ì ìš©ëœ ìµœì í™” ì„¤ì •:")
                logger.info("  - ì¸ë±ì‹± ì„ê³„ê°’: 20K í¬ì¸íŠ¸")
                logger.info("  - ë©”ëª¨ë¦¬ ë§¤í•‘: 50K í¬ì¸íŠ¸ë¶€í„°")
                logger.info("  - ìµœëŒ€ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°: 200K í¬ì¸íŠ¸")
                logger.info("  - HNSW ì¸ë±ìŠ¤: m=16, ef_construct=100")
                logger.info("  - INT8 ì–‘ìí™” í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)")
                logger.info("  - ë””ìŠ¤í¬ payload ì €ì¥ í™œì„±í™”")
                return True
            else:
                logger.debug(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ì´ë¯¸ ì¡´ì¬")
                return False
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def generate_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            embeddings = self.get_embeddings()
            vector = await embeddings.aembed_query(text)
            logger.debug(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(vector)} ì°¨ì›")
            return vector
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    async def generate_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            embeddings = self.get_embeddings()
            vectors = await embeddings.aembed_documents(texts)
            logger.debug(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(vectors)}ê°œ ë²¡í„°")
            return vectors
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    @MetricsCollector.track_db_query("qdrant", "upsert")
    async def upsert_points(
        self, 
        points: List[PointStruct], 
        wait: bool = True
    ) -> Dict[str, Any]:
        """í¬ì¸íŠ¸ë“¤ì„ Qdrantì— ì‚½ì…/ì—…ë°ì´íŠ¸"""
        try:
            client = await self.get_async_client()
            result = await client.upsert(
                collection_name=self.collection_name,
                wait=wait,
                points=points
            )
            logger.debug(f"{len(points)}ê°œ í¬ì¸íŠ¸ upsert ì™„ë£Œ")
            return {"status": "success", "operation_id": result.operation_id}
        except Exception as e:
            logger.error(f"í¬ì¸íŠ¸ upsert ì‹¤íŒ¨: {e}")
            raise

    @MetricsCollector.track_db_query("qdrant", "batch_upsert_optimized")
    async def upsert_points_batch_optimized(
        self, 
        points: List[PointStruct], 
        batch_size: int = 100,
        wait: bool = False,
        parallel_batches: int = 3
    ) -> Dict[str, Any]:
        """ğŸš€ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ìœ„í•œ ìµœì í™”ëœ ë°°ì¹˜ ì—…ë¡œë“œ"""
        try:
            if not points:
                return {"status": "success", "processed": 0}
            
            client = await self.get_async_client()
            total_points = len(points)
            
            # í¬ì¸íŠ¸ë“¤ì„ ë°°ì¹˜ë¡œ ë¶„í• 
            batches = [
                points[i:i + batch_size] 
                for i in range(0, total_points, batch_size)
            ]
            
            logger.info(f"ğŸš€ ë°°ì¹˜ ìµœì í™” ì—…ë¡œë“œ ì‹œì‘: {total_points}ê°œ í¬ì¸íŠ¸, {len(batches)}ê°œ ë°°ì¹˜")
            
            # ë³‘ë ¬ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´
            semaphore = asyncio.Semaphore(parallel_batches)
            operation_ids = []
            
            async def process_batch(batch_points: List[PointStruct], batch_idx: int):
                async with semaphore:
                    try:
                        result = await client.upsert(
                            collection_name=self.collection_name,
                            wait=wait,
                            points=batch_points
                        )
                        logger.debug(f"ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì™„ë£Œ: {len(batch_points)}ê°œ í¬ì¸íŠ¸")
                        return result.operation_id
                    except Exception as e:
                        logger.error(f"ë°°ì¹˜ {batch_idx + 1} ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
                        raise
            
            # ëª¨ë“  ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
            tasks = [
                process_batch(batch, idx) 
                for idx, batch in enumerate(batches)
            ]
            
            operation_ids = await asyncio.gather(*tasks)
            
            logger.info(f"âœ… ë°°ì¹˜ ìµœì í™” ì—…ë¡œë“œ ì™„ë£Œ: {total_points}ê°œ í¬ì¸íŠ¸ ì²˜ë¦¬ë¨")
            return {
                "status": "success", 
                "processed": total_points,
                "batches": len(batches),
                "operation_ids": operation_ids
            }
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ìµœì í™” ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    async def optimize_collection(self) -> Dict[str, Any]:
        """ğŸ§¹ ì»¬ë ‰ì…˜ ìµœì í™” ì‹¤í–‰ (Vacuum, Merge ë“±)"""
        try:
            client = await self.get_async_client()
            
            logger.info("ğŸ§¹ ì»¬ë ‰ì…˜ ìµœì í™” ì‹œì‘...")
            
            # 1. ì‚­ì œëœ ë²¡í„° ì •ë¦¬ (Vacuum)
            logger.info("1ï¸âƒ£ ì‚­ì œëœ ë²¡í„° ì •ë¦¬ ì¤‘...")
            vacuum_result = await client.update_collection(
                collection_name=self.collection_name,
                optimizer_config=models.OptimizersConfigDiff(
                    deleted_threshold=0.1,  # ì„ì‹œë¡œ ë‚®ì¶°ì„œ ê°•ì œ ì •ë¦¬
                    vacuum_min_vector_number=1
                )
            )
            
            # 2. ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
            logger.info("2ï¸âƒ£ ì¸ë±ìŠ¤ ìµœì í™” ì¤‘...")
            # ì ì‹œ í›„ ë‹¤ì‹œ ì›ë˜ ì„¤ì •ìœ¼ë¡œ ë³µì›
            await asyncio.sleep(1)
            restore_result = await client.update_collection(
                collection_name=self.collection_name,
                optimizer_config=models.OptimizersConfigDiff(
                    deleted_threshold=0.7,  # ì›ë˜ ì„¤ì •ìœ¼ë¡œ ë³µì›
                    vacuum_min_vector_number=1000
                )
            )
            
            # 3. ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒë¡œ ìµœì í™” ê²°ê³¼ í™•ì¸
            collection_info = await client.get_collection(self.collection_name)
            
            logger.info("âœ… ì»¬ë ‰ì…˜ ìµœì í™” ì™„ë£Œ")
            logger.info(f"  - ì´ í¬ì¸íŠ¸ ìˆ˜: {collection_info.points_count}")
            logger.info(f"  - ì¸ë±ìŠ¤ ìƒíƒœ: {collection_info.status}")
            
            return {
                "status": "success",
                "points_count": collection_info.points_count,
                "collection_status": collection_info.status,
                "vacuum_operation_id": vacuum_result.operation_id if vacuum_result else None,
                "restore_operation_id": restore_result.operation_id if restore_result else None
            }
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìµœì í™” ì‹¤íŒ¨: {e}")
            raise

    async def get_storage_stats(self) -> Dict[str, Any]:
        """ğŸ“Š ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰ ë° ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        try:
            client = await self.get_async_client()
            
            # ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ
            collection_info = await client.get_collection(self.collection_name)
            
            # í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                cluster_info = await client.cluster_info()
            except:
                cluster_info = None
            
            stats = {
                "collection_name": self.collection_name,
                "points_count": collection_info.points_count,
                "segments_count": len(collection_info.segments) if collection_info.segments else 0,
                "status": collection_info.status,
                "optimizer_status": collection_info.optimizer_status,
                "vectors_count": collection_info.vectors_count if hasattr(collection_info, 'vectors_count') else None,
                "indexed_vectors_count": collection_info.indexed_vectors_count if hasattr(collection_info, 'indexed_vectors_count') else None,
            }
            
            if cluster_info:
                stats["cluster_status"] = cluster_info
            
            logger.debug(f"ìŠ¤í† ë¦¬ì§€ í†µê³„ ì¡°íšŒ ì™„ë£Œ: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"ìŠ¤í† ë¦¬ì§€ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
    
    async def upsert_vector_async(
        self, 
        vector_id: str, 
        vector: List[float], 
        metadata: Optional[Dict[str, Any]] = None,
        wait: bool = True
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ ë²¡í„°ë¥¼ Qdrantì— ì‚½ì…/ì—…ë°ì´íŠ¸ (batch_processor í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ)"""
        try:
            # ì´ë¯¸ ìœ íš¨í•œ UUIDì¸ì§€ í™•ì¸
            try:
                uuid.UUID(vector_id)
                valid_uuid = vector_id  # ì´ë¯¸ ìœ íš¨í•œ UUID
            except ValueError:
                # ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ë³€í™˜ (fallback to old logic)
                valid_uuid = ensure_valid_uuid(vector_id)
            
            point = PointStruct(
                id=valid_uuid,
                vector=vector,
                payload=metadata or {}
            )
            
            client = await self.get_async_client()
            result = await client.upsert(
                collection_name=self.collection_name,
                wait=wait,
                points=[point]
            )
            logger.debug(f"ë²¡í„° upsert ì™„ë£Œ: ID={vector_id} -> UUID={valid_uuid}")
            return {"status": "success", "operation_id": result.operation_id, "uuid": valid_uuid}
        except Exception as e:
            logger.error(f"ë²¡í„° upsert ì‹¤íŒ¨ (ID: {vector_id}): {e}")
            raise
    
    async def delete_points(
        self, 
        point_ids: List[str], 
        wait: bool = True
    ) -> Dict[str, Any]:
        """í¬ì¸íŠ¸ë“¤ì„ Qdrantì—ì„œ ì‚­ì œ"""
        try:
            client = await self.get_async_client()
            result = await client.delete(
                collection_name=self.collection_name,
                wait=wait,
                points_selector=models.PointIdsList(
                    points=point_ids
                )
            )
            logger.debug(f"{len(point_ids)}ê°œ í¬ì¸íŠ¸ ì‚­ì œ ì™„ë£Œ")
            return {"status": "success", "operation_id": result.operation_id}
        except Exception as e:
            logger.error(f"í¬ì¸íŠ¸ ì‚­ì œ ì‹¤íŒ¨: {e}")
            raise
    
    @MetricsCollector.track_db_query("qdrant", "search")
    async def search_points(
        self,
        query_vector: List[float],
        limit: int = 10,
        filter_conditions: Optional[Filter] = None,
        with_payload: bool = True,
        with_vectors: bool = False
    ) -> List[ScoredPoint]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
        try:
            client = await self.get_async_client()
            results = await client.search(
                collection_name=self.collection_name,
                query_vector=query_vector,
                limit=limit,
                query_filter=filter_conditions,
                with_payload=with_payload,
                with_vectors=with_vectors
            )
            logger.debug(f"ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise

    async def search_similar_vectors(
        self,
        query_vector: List[float],
        limit: int = 10,
        filter_conditions: Optional[Filter] = None,
        with_payload: bool = True,
        with_vectors: bool = False
    ) -> List[ScoredPoint]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­)"""
        return await self.search_points(
            query_vector=query_vector,
            limit=limit,
            filter_conditions=filter_conditions,
            with_payload=with_payload,
            with_vectors=with_vectors
        )
    
    async def get_points(
        self, 
        point_ids: List[str], 
        with_payload: bool = True, 
        with_vectors: bool = False
    ) -> List[Record]:
        """íŠ¹ì • í¬ì¸íŠ¸ë“¤ ì¡°íšŒ"""
        try:
            client = await self.get_async_client()
            results = await client.retrieve(
                collection_name=self.collection_name,
                ids=point_ids,
                with_payload=with_payload,
                with_vectors=with_vectors
            )
            logger.debug(f"{len(results)}ê°œ í¬ì¸íŠ¸ ì¡°íšŒ ì™„ë£Œ")
            return results
        except Exception as e:
            logger.error(f"í¬ì¸íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
    
    async def count_points(self) -> int:
        """ì»¬ë ‰ì…˜ì˜ ì´ í¬ì¸íŠ¸ ìˆ˜ ë°˜í™˜"""
        try:
            client = await self.get_async_client()
            result = await client.count(collection_name=self.collection_name)
            count = result.count
            logger.debug(f"ì´ í¬ì¸íŠ¸ ìˆ˜: {count}")
            return count
        except Exception as e:
            logger.error(f"í¬ì¸íŠ¸ ì¹´ìš´íŠ¸ ì‹¤íŒ¨: {e}")
            raise
    
    @MetricsCollector.track_db_query("qdrant", "list_collections")
    async def list_collections(self) -> List[str]:
        """ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡ ë°˜í™˜"""
        try:
            client = await self.get_async_client()
            collections = await client.get_collections()
            collection_names = [c.name for c in collections.collections]
            logger.debug(f"ì»¬ë ‰ì…˜ ëª©ë¡: {collection_names}")
            return collection_names
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise

    async def get_collection_info(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            client = await self.get_async_client()
            info = await client.get_collection(self.collection_name)
            logger.debug("ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì™„ë£Œ")
            return {
                "status": info.status,
                "optimizer_status": info.optimizer_status,
                "vectors_count": info.vectors_count,
                "points_count": info.points_count,
                "config": info.config
            }
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise
    
    async def health_check(self) -> bool:
        """Qdrant ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            client = await self.get_async_client()
            collections = await client.get_collections()
            return len(collections.collections) >= 0
        except Exception as e:
            logger.error(f"Qdrant í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ"""
        if self._async_client:
            await self._async_client.close()
            logger.info("Qdrant ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
        if self._client:
            self._client.close()
            logger.info("Qdrant ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
qdrant_manager = QdrantManager()

# í¸ì˜ í•¨ìˆ˜ë“¤
async def get_async_client() -> AsyncQdrantClient:
    """ë¹„ë™ê¸° Qdrant í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    return await qdrant_manager.get_async_client()

def get_sync_client() -> QdrantClient:
    """ë™ê¸° Qdrant í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    return qdrant_manager.get_sync_client()

async def generate_embedding(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    return await qdrant_manager.generate_embedding(text)