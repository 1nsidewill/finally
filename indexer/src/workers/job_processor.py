"""
Job Processor for Redis Queue Worker

PostgreSQLê³¼ Qdrant ê°„ ë°ì´í„° ë™ê¸°í™”ë¥¼ ìœ„í•œ ìž‘ì—… ì²˜ë¦¬ ëª¨ë“ˆ
- SYNC: ìƒˆë¡œìš´ ì œí’ˆ ì¶”ê°€/ì „ì²´ ë™ê¸°í™”
- UPDATE: ê¸°ì¡´ ì œí’ˆ ì •ë³´ ë³€ê²½  
- DELETE: ì œí’ˆ ì‚­ì œ
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import json
import uuid

from src.config import get_settings
from src.database.postgresql import PostgreSQLManager
from src.database.qdrant import QdrantManager
from src.services.text_preprocessor import ProductTextPreprocessor
from src.services.embedding_service import EmbeddingService
from src.services.error_handler import ErrorHandler, ErrorContext

logger = logging.getLogger(__name__)

class JobType(Enum):
    """ìž‘ì—… íƒ€ìž…"""
    SYNC = "sync"       # ìƒˆë¡œìš´ ì œí’ˆ ì¶”ê°€/ë™ê¸°í™”
    UPDATE = "update"   # ê¸°ì¡´ ì œí’ˆ ì •ë³´ ì—…ë°ì´íŠ¸
    DELETE = "delete"   # ì œí’ˆ ì‚­ì œ

@dataclass
class JobResult:
    """ìž‘ì—… ì²˜ë¦¬ ê²°ê³¼"""
    job_id: str
    job_type: JobType
    product_id: str
    success: bool
    message: str
    processing_time: float
    error: Optional[str] = None
    vector_id: Optional[str] = None

@dataclass
class ProductData:
    """ì œí’ˆ ë°ì´í„° êµ¬ì¡°"""
    pid: str
    title: str
    price: Optional[int] = None
    content: Optional[str] = None
    year: Optional[int] = None
    mileage: Optional[int] = None
    page_url: Optional[str] = None
    images: List[str] = None
    
    def __post_init__(self):
        # íŽ˜ì´ì§€ URL ìƒì„±
        if not self.page_url and self.pid:
            self.page_url = f"https://m.bunjang.co.kr/products/{self.pid}"
        
        if self.images is None:
            self.images = []

class JobProcessor:
    """Redis Queue Job Processor"""
    
    def __init__(self):
        self.settings = get_settings()
        self.postgresql_manager = None
        self.qdrant_manager = None
        self.text_preprocessor = ProductTextPreprocessor()
        self.embedding_service = EmbeddingService()
        self.error_handler = ErrorHandler()
        
        # í†µê³„
        self.stats = {
            'total_processed': 0,
            'sync_count': 0,
            'update_count': 0,
            'delete_count': 0,
            'success_count': 0,
            'error_count': 0,
        }
    
    async def initialize(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        try:
            # PostgreSQL ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.postgresql_manager = PostgreSQLManager()
            # PostgreSQLì€ lazy loadingì´ë¯€ë¡œ pool ìƒì„± í…ŒìŠ¤íŠ¸
            await self.postgresql_manager.get_pool()
            
            # Qdrant ë§¤ë‹ˆì € ì´ˆê¸°í™”
            self.qdrant_manager = QdrantManager()
            # QdrantëŠ” lazy loadingì´ë¯€ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ë° ì»¬ë ‰ì…˜ í™•ì¸
            await self.qdrant_manager.get_async_client()
            await self.qdrant_manager.create_collection_if_not_exists()
            
            # ErrorHandler ì´ˆê¸°í™”
            await self.error_handler.initialize()
            
            logger.info("âœ… JobProcessor ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ JobProcessor ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.postgresql_manager:
            await self.postgresql_manager.close()
        if self.qdrant_manager:
            await self.qdrant_manager.close()
        # EmbeddingServiceëŠ” close ë©”ì„œë“œê°€ ì—†ìŒ (stateless)
        if self.error_handler:
            await self.error_handler.close()
        
        logger.info("ðŸ”¹ JobProcessor ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    
    async def process_job(self, job_data: Dict[str, Any]) -> JobResult:
        """ë‹¨ì¼ ìž‘ì—… ì²˜ë¦¬"""
        import time
        start_time = time.time()
        
        try:
            # ìž‘ì—… ë°ì´í„° íŒŒì‹±
            job_id = job_data.get('id', str(uuid.uuid4()))
            job_type_str = job_data.get('type', '').lower()
            product_id = str(job_data.get('product_id', ''))
            
            # ìž‘ì—… íƒ€ìž… ê²€ì¦
            try:
                job_type = JobType(job_type_str)
            except ValueError:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìž‘ì—… íƒ€ìž…: {job_type_str}")
            
            if not product_id:
                raise ValueError("product_idê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            # ìž‘ì—… íƒ€ìž…ë³„ ì²˜ë¦¬
            result = None
            if job_type == JobType.SYNC:
                result = await self._process_sync(job_id, product_id)
            elif job_type == JobType.UPDATE:
                result = await self._process_update(job_id, product_id)
            elif job_type == JobType.DELETE:
                result = await self._process_delete(job_id, product_id)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['total_processed'] += 1
            self.stats[f'{job_type.value}_count'] += 1
            if result.success:
                self.stats['success_count'] += 1
            else:
                self.stats['error_count'] += 1
            
            processing_time = time.time() - start_time
            result.processing_time = processing_time
            
            logger.info(f"âœ… ìž‘ì—… ì²˜ë¦¬ ì™„ë£Œ: {job_type.value} - {product_id} ({processing_time:.2f}s)")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = str(e)
            
            # ErrorHandlerë¡œ ì˜¤ë¥˜ ì²˜ë¦¬
            try:
                context = ErrorContext(
                    job_id=job_id if 'job_id' in locals() else str(uuid.uuid4()),
                    job_type=job_type.value if 'job_type' in locals() else 'unknown',
                    product_id=product_id if 'product_id' in locals() else '',
                    operation_step='job_processing',
                    additional_data={
                        'processing_time': processing_time,
                        'job_data': job_data
                    }
                )
                await self.error_handler.handle_error(e, context)
            except Exception as error_handling_exception:
                logger.error(f"ðŸš¨ ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {error_handling_exception}")
            
            self.stats['total_processed'] += 1
            self.stats['error_count'] += 1
            
            logger.error(f"âŒ ìž‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {job_id} - {error_msg}")
            
            return JobResult(
                job_id=job_id if 'job_id' in locals() else str(uuid.uuid4()),
                job_type=job_type if 'job_type' in locals() else JobType.SYNC,
                product_id=product_id if 'product_id' in locals() else '',
                success=False,
                message=f"ìž‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}",
                processing_time=processing_time,
                error=error_msg
            )
    
    async def process_jobs_batch(self, jobs: List[Dict[str, Any]]) -> List[JobResult]:
        """ë°°ì¹˜ ìž‘ì—… ì²˜ë¦¬"""
        if not jobs:
            return []
        
        logger.info(f"ðŸ”„ ë°°ì¹˜ ìž‘ì—… ì²˜ë¦¬ ì‹œìž‘: {len(jobs)}ê°œ")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [self.process_job(job) for job in jobs]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                job_data = jobs[i] if i < len(jobs) else {}
                error_result = JobResult(
                    job_id=job_data.get('id', str(uuid.uuid4())),
                    job_type=JobType.SYNC,
                    product_id=str(job_data.get('product_id', '')),
                    success=False,
                    message=f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {result}",
                    processing_time=0.0,
                    error=str(result)
                )
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        success_count = sum(1 for r in processed_results if r.success)
        logger.info(f"âœ… ë°°ì¹˜ ìž‘ì—… ì™„ë£Œ: {success_count}/{len(jobs)} ì„±ê³µ")
        
        return processed_results
    
    async def _fetch_product_data(self, product_id: str) -> ProductData:
        """PostgreSQLì—ì„œ ì œí’ˆ ë°ì´í„° ì¡°íšŒ"""
        try:
            async with self.postgresql_manager.get_connection() as conn:
                # product í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
                product_query = """
                    SELECT pid, title, price, content, year, mileage
                    FROM product 
                    WHERE pid = $1
                """
                product_row = await conn.fetchrow(product_query, product_id)
                
                if not product_row:
                    raise ValueError(f"ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {product_id}")
                
                # file í…Œì´ë¸”ì—ì„œ ì´ë¯¸ì§€ URL ì¡°íšŒ (product_uidë¡œ ì¡°ì¸)
                file_query = """
                    SELECT url, count 
                    FROM file 
                    WHERE product_uid = $1 
                    ORDER BY count
                """
                file_results = await conn.fetch(file_query, product_id)
                
                # ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
                images = []
                for file_row in file_results:
                    url_template = file_row['url']
                    count = file_row['count']
                    # {cnt}ë¥¼ ì‹¤ì œ count ê°’ìœ¼ë¡œ êµì²´
                    if '{cnt}' in url_template:
                        image_url = url_template.replace('{cnt}', str(count))
                        images.append(image_url)
                    else:
                        images.append(url_template)
                
                # ProductData ê°ì²´ ìƒì„±
                product_data = ProductData(
                    pid=product_row['pid'],
                    title=product_row['title'] or '',
                    price=product_row['price'],
                    content=product_row['content'] or '',
                    year=product_row['year'],
                    mileage=product_row['mileage'],
                    images=images
                )
                
                logger.debug(f"ðŸ” ì œí’ˆ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {product_id} (ì´ë¯¸ì§€ {len(images)}ê°œ)")
                return product_data
            
        except Exception as e:
            logger.error(f"âŒ ì œí’ˆ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {product_id} - {e}")
            raise
    
    async def _process_sync(self, job_id: str, product_id: str) -> JobResult:
        """SYNC ìž‘ì—… ì²˜ë¦¬: ìƒˆë¡œìš´ ì œí’ˆ ì¶”ê°€/ë™ê¸°í™”"""
        operation_step = "sync_init"
        
        try:
            # 1. PostgreSQLì—ì„œ ì œí’ˆ ë°ì´í„° ì¡°íšŒ
            operation_step = "data_fetch"
            product_data = await self._fetch_product_data(product_id)
            
            # 2. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            operation_step = "text_preprocessing"
            processed_text = self.text_preprocessor.preprocess_product_data({
                'title': product_data.title,
                'year': product_data.year,
                'price': product_data.price,
                'mileage': product_data.mileage,
                'content': product_data.content
            })
            
            # 3. ìž„ë² ë”© ìƒì„±
            operation_step = "embedding_generation"
            embedding = await self.embedding_service.get_embedding_async(processed_text)
            
            # 4. Qdrantì— ë²¡í„° ì‚½ìž…
            operation_step = "vector_insertion"
            vector_id = str(uuid.uuid4())
            metadata = {
                'product_id': product_data.pid,
                'title': product_data.title,
                'price': product_data.price,
                'year': product_data.year,
                'mileage': product_data.mileage,
                'page_url': product_data.page_url,
                'images': product_data.images,
                'processed_text': processed_text,
                'synced_at': asyncio.get_event_loop().time()
            }
            
            await self.qdrant_manager.upsert_vector_async(
                vector_id=vector_id,
                vector=embedding,
                metadata=metadata
            )
            
            return JobResult(
                job_id=job_id,
                job_type=JobType.SYNC,
                product_id=product_id,
                success=True,
                message=f"ì œí’ˆ ë™ê¸°í™” ì™„ë£Œ: {product_data.title}",
                processing_time=0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°ë¨
                vector_id=vector_id
            )
            
        except Exception as e:
            # ë‹¨ê³„ë³„ ì˜¤ë¥˜ ì²˜ë¦¬
            try:
                context = ErrorContext(
                    job_id=job_id,
                    job_type='sync',
                    product_id=product_id,
                    operation_step=operation_step,
                    additional_data={
                        'processed_text': processed_text if 'processed_text' in locals() else None,
                        'product_data': product_data.__dict__ if 'product_data' in locals() else None
                    }
                )
                await self.error_handler.handle_error(e, context)
            except Exception as error_handling_exception:
                logger.error(f"ðŸš¨ SYNC ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {error_handling_exception}")
            
            return JobResult(
                job_id=job_id,
                job_type=JobType.SYNC,
                product_id=product_id,
                success=False,
                message=f"SYNC ì‹¤íŒ¨ ({operation_step}): {str(e)}",
                processing_time=0.0,
                error=str(e)
            )
    
    async def _process_update(self, job_id: str, product_id: str) -> JobResult:
        """UPDATE ìž‘ì—… ì²˜ë¦¬: ê¸°ì¡´ ì œí’ˆ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            # 1. Qdrantì—ì„œ ê¸°ì¡´ ë²¡í„° ì°¾ê¸°
            existing_vectors = await self.qdrant_manager.search_vectors(
                query_text="",  # ë¹ˆ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
                filter_conditions={"product_id": product_id},
                limit=1
            )
            
            if not existing_vectors:
                # ê¸°ì¡´ ë²¡í„°ê°€ ì—†ìœ¼ë©´ SYNC ìž‘ì—…ìœ¼ë¡œ ì²˜ë¦¬
                logger.info(f"ðŸ”„ ê¸°ì¡´ ë²¡í„° ì—†ìŒ, SYNCë¡œ ì „í™˜: {product_id}")
                return await self._process_sync(job_id, product_id)
            
            # 2. ìƒˆë¡œìš´ ì œí’ˆ ë°ì´í„° ì¡°íšŒ
            product_data = await self._fetch_product_data(product_id)
            
            # 3. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            processed_text = self.text_preprocessor.preprocess_product_data({
                'title': product_data.title,
                'year': product_data.year,
                'price': product_data.price,
                'mileage': product_data.mileage,
                'content': product_data.content
            })
            
            # 4. ìƒˆë¡œìš´ ìž„ë² ë”© ìƒì„±
            embedding = await self.embedding_service.get_embedding_async(processed_text)
            
            # 5. ê¸°ì¡´ ë²¡í„° ì—…ë°ì´íŠ¸
            vector_id = existing_vectors[0]['id']
            metadata = {
                'product_id': product_data.pid,
                'title': product_data.title,
                'price': product_data.price,
                'year': product_data.year,
                'mileage': product_data.mileage,
                'page_url': product_data.page_url,
                'images': product_data.images,
                'processed_text': processed_text,
                'updated_at': asyncio.get_event_loop().time()
            }
            
            await self.qdrant_manager.upsert_vector_async(
                vector_id=vector_id,
                vector=embedding,
                metadata=metadata
            )
            
            return JobResult(
                job_id=job_id,
                job_type=JobType.UPDATE,
                product_id=product_id,
                success=True,
                message=f"ì œí’ˆ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {product_data.title}",
                processing_time=0.0,
                vector_id=vector_id
            )
            
        except Exception as e:
            return JobResult(
                job_id=job_id,
                job_type=JobType.UPDATE,
                product_id=product_id,
                success=False,
                message=f"UPDATE ì‹¤íŒ¨: {str(e)}",
                processing_time=0.0,
                error=str(e)
            )
    
    async def _process_delete(self, job_id: str, product_id: str) -> JobResult:
        """DELETE ìž‘ì—… ì²˜ë¦¬: ì œí’ˆ ì‚­ì œ"""
        try:
            # 1. Qdrantì—ì„œ í•´ë‹¹ ì œí’ˆì˜ ëª¨ë“  ë²¡í„° ì°¾ê¸°
            existing_vectors = await self.qdrant_manager.search_vectors(
                query_text="",  # ë¹ˆ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
                filter_conditions={"product_id": product_id},
                limit=100  # í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë²¡í„°ë“¤ê¹Œì§€ ëª¨ë‘ ì°¾ê¸°
            )
            
            if not existing_vectors:
                return JobResult(
                    job_id=job_id,
                    job_type=JobType.DELETE,
                    product_id=product_id,
                    success=True,
                    message=f"ì‚­ì œí•  ë²¡í„°ê°€ ì—†ìŒ: {product_id}",
                    processing_time=0.0
                )
            
            # 2. ëª¨ë“  ê´€ë ¨ ë²¡í„° ì‚­ì œ
            deleted_count = 0
            for vector in existing_vectors:
                try:
                    await self.qdrant_manager.delete_vector(vector['id'])
                    deleted_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ ë²¡í„° ì‚­ì œ ì‹¤íŒ¨: {vector['id']} - {e}")
            
            return JobResult(
                job_id=job_id,
                job_type=JobType.DELETE,
                product_id=product_id,
                success=True,
                message=f"ì œí’ˆ ì‚­ì œ ì™„ë£Œ: {deleted_count}ê°œ ë²¡í„° ì‚­ì œ",
                processing_time=0.0
            )
            
        except Exception as e:
            return JobResult(
                job_id=job_id,
                job_type=JobType.DELETE,
                product_id=product_id,
                success=False,
                message=f"DELETE ì‹¤íŒ¨: {str(e)}",
                processing_time=0.0,
                error=str(e)
            )
    
    def get_stats(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            'success_rate': (
                self.stats['success_count'] / self.stats['total_processed'] * 100
                if self.stats['total_processed'] > 0 else 0
            )
        }
    
    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        for key in self.stats:
            self.stats[key] = 0 