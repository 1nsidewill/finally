import os
import time
import logging
from datetime import datetime

from fastapi import APIRouter, HTTPException, status, Depends
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.prompts import PromptTemplate

from src.config import get_settings
from src.api.schema import PropertyItems, QueryRequest, QueryResponse
from src.api.document_utils import format_docs, load_txt_documents
from src.api.utils import load_prompts
from src.auth.user_service import get_current_user

# ë¡œê±° ì„¤ì •
logger = logging.getLogger("api")
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# ì„¤ì • ë¡œë“œ
config = get_settings()
api_router = APIRouter()

# í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ ë¡œë“œ
PROMPTS = load_prompts()

# ë²¡í„°ìŠ¤í† ì–´ ë° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
logger.info("ğŸ”„ ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")
DATA_DIR = os.path.join(os.path.dirname(__file__), "../../data")
docs_list = load_txt_documents(DATA_DIR)
vectorstore = Chroma.from_documents(
    documents=docs_list,
    collection_name="rag-chroma",
    embedding=OpenAIEmbeddings(openai_api_key=config.OPENAI_API_KEY, model="text-embedding-3-large"),
)
retriever = vectorstore.as_retriever()
logger.info(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ. ë¬¸ì„œ {len(docs_list)}ê°œ ë¡œë“œë¨")

@api_router.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest, user=Depends(get_current_user)):
    """
    ë°”ì´í¬ ë§¤ë¬¼ ì¶”ì²œ API ì—”ë“œí¬ì¸íŠ¸
    
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ì„±ì´ ë†’ì€ ë§¤ë¬¼ì„ ì¶”ì²œí•˜ê³  ìˆœìœ„ë¥¼ ë§¤ê²¨ ì œê³µí•©ë‹ˆë‹¤.
    """
    request_id = f"req_{int(time.time())}"
    start_time = time.time()
    logger.info(f"ğŸ” [{request_id}] ê²€ìƒ‰ ìš”ì²­ ì‹œì‘ - ì‚¬ìš©ì: {user}, ì¿¼ë¦¬: '{request.question}'")
    
    try:
        # YAMLì—ì„œ ë¡œë“œí•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
        bike_prompt = PROMPTS.get("bike_recommendation_prompt", "")
        if not bike_prompt:
            logger.error(f"âŒ [{request_id}] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            raise ValueError("í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        prompt = PromptTemplate.from_template(
            bike_prompt,
            template_format="jinja2"
        )
        
        logger.info(f"ğŸ“„ [{request_id}] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        
        # LLM ëª¨ë¸ ì„¤ì • ë° êµ¬ì¡°í™”ëœ ì¶œë ¥ êµ¬ì„±
        llm_model = ChatOpenAI(
            model_name="gpt-4o",
            api_key=config.OPENAI_API_KEY,
            temperature=0.1
        ).with_structured_output(PropertyItems)

        # ì¶”ì²œ ì²´ì¸ êµ¬ì„±
        chain = (
            {
                "input_query": lambda x: x,
                "context": retriever | format_docs
            }
            | prompt
            | llm_model
        )
        
        # LLMì— ì¶”ì²œ ìš”ì²­
        logger.info(f"ğŸ¤– [{request_id}] LLMì— ì¶”ì²œ ìš”ì²­ ì¤‘...")
        property_items = await chain.ainvoke(request.question)
        
        # ìˆœìœ„ì— ë”°ë¼ ê²°ê³¼ ì •ë ¬
        sorted_items = sorted(property_items.items, key=lambda item: item.rank)
        
        # ì‘ë‹µ êµ¬ì„±
        response = QueryResponse(
            result=sorted_items,
            message="ì„±ê³µì ìœ¼ë¡œ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤",
            success=True
        )
        
        # ì²˜ë¦¬ ì™„ë£Œ ë¡œê¹…
        process_time = time.time() - start_time
        logger.info(f"âœ… [{request_id}] ê²€ìƒ‰ ì™„ë£Œ: {len(sorted_items)}ê°œ ë§¤ë¬¼ ì¶”ì²œ, ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        
        return response
        
    except Exception as e:
        # ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹…
        process_time = time.time() - start_time
        if isinstance(e, ValueError):
            logger.error(f"âŒ [{request_id}] ì˜ëª»ëœ ìš”ì²­: {str(e)}, ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
        elif isinstance(e, KeyError):
            logger.error(f"âŒ [{request_id}] ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}, ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
            raise HTTPException(status_code=status.HTTP_422_UNPROCESSABLE_ENTITY, detail=str(e))
        else:
            logger.error(f"âŒ [{request_id}] ì„œë²„ ì˜¤ë¥˜: {str(e)}, ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
                detail="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: " + str(e)
            )
